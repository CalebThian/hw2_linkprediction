{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223ed502",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a95b66b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_undirected, from_scipy_sparse_matrix,dense_to_sparse,is_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb017ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E370</td>\n",
       "      <td>26</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E667</td>\n",
       "      <td>196</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3190</td>\n",
       "      <td>739</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E848</td>\n",
       "      <td>576</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2161</td>\n",
       "      <td>466</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   to  from\n",
       "0   E370   26   317\n",
       "1   E667  196   323\n",
       "2  E3190  739   468\n",
       "3   E848  576   156\n",
       "4  E2161  466   199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"hw2_data/\"\n",
    "dss = ['dataset1','dataset2','dataset3'] #datasets\n",
    "dataset = dict()\n",
    "for ds in dss:\n",
    "    dataset[ds] = dict()\n",
    "    dataset[ds]['content'] = pd.read_csv(path+ds+\"/content.csv\",delimiter = '\\t',header = None)\n",
    "    dataset[ds]['train'] = pd.read_csv(path+ds+\"/train.csv\",delimiter = ',')\n",
    "    dataset[ds]['test'] = pd.read_csv(path+ds+\"/test.csv\",delimiter = ',')\n",
    "    dataset[ds]['upload'] = pd.read_csv(path+ds+\"/upload.csv\",delimiter = ',')\n",
    "dataset[dss[2]]['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cbe4ee",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7ef884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 1434)\n",
      "2708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1433,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[dss[0]]['content'].shape)\n",
    "print(len(dataset[dss[0]]['content']))\n",
    "np.array(dataset[dss[0]]['content'].iloc[0,1:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135588a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8686, 4)\n",
      "8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2397"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[dss[0]]['train'].shape)\n",
    "print(len(dataset[dss[0]]['train']))\n",
    "dataset[dss[0]]['train'].loc[1,'to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e3a7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edge(0,1,label=0)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70acf09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example:\n",
    "Content = dataset[dss[0]]['content']\n",
    "Train = dataset[dss[0]]['train']\n",
    "Test = dataset[dss[0]]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c3fff40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1434)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d7ee054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E10255</td>\n",
       "      <td>2397</td>\n",
       "      <td>1144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E5926</td>\n",
       "      <td>2450</td>\n",
       "      <td>1312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E7506</td>\n",
       "      <td>1808</td>\n",
       "      <td>2472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E7406</td>\n",
       "      <td>2030</td>\n",
       "      <td>2494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E10087</td>\n",
       "      <td>1767</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>E1204</td>\n",
       "      <td>2508</td>\n",
       "      <td>2278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>E4741</td>\n",
       "      <td>1879</td>\n",
       "      <td>1443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683</th>\n",
       "      <td>E9256</td>\n",
       "      <td>171</td>\n",
       "      <td>1711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8684</th>\n",
       "      <td>E4322</td>\n",
       "      <td>633</td>\n",
       "      <td>2440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>E4434</td>\n",
       "      <td>122</td>\n",
       "      <td>1222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4324 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    to  from  label\n",
       "1     E10255  2397  1144      1\n",
       "4      E5926  2450  1312      1\n",
       "6      E7506  1808  2472      1\n",
       "8      E7406  2030  2494      1\n",
       "14    E10087  1767     4      1\n",
       "...      ...   ...   ...    ...\n",
       "8680   E1204  2508  2278      1\n",
       "8682   E4741  1879  1443      1\n",
       "8683   E9256   171  1711      1\n",
       "8684   E4322   633  2440      1\n",
       "8685   E4434   122  1222      1\n",
       "\n",
       "[4324 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[Train['label']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f877db9",
   "metadata": {},
   "source": [
    "---\n",
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ee8922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f3608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bcf66",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9b17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor(x):\n",
    "    return torch.div(x, 1, rounding_mode='trunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8395787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    # Row-normalize feature matrix and convert to tuple representation\n",
    "    # Because the datasets only have binary features, row-normalize is unnecessary\n",
    "    rowsum = np.array(features.sum(1),dtype = np.float32)\n",
    "    rowsum = (rowsum==0)*1+rowsum\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa0fd66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(content,train):\n",
    "    G = nx.DiGraph()\n",
    "    graph_node_features_dict = dict()\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        #graph_node_features_dict[content.iloc[i,0]] = np.array(content.iloc[i,1:])\n",
    "        G.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        \n",
    "    for i in range(len(train)):\n",
    "        # Adding nodes into G\n",
    "        '''\n",
    "        if train.loc[i,'from'] not in G:\n",
    "            G.add_node(train.loc[i,'from'],features = graph_node_features_dict[train.loc[i,'from']])\n",
    "        if train.loc[i,'to'] not in G:\n",
    "            G.add_node(train.loc[i,'to'],features = graph_node_features_dict[train.loc[i,'to']])\n",
    "        ''' \n",
    "        # Adding edges\n",
    "        G.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "    \n",
    "    adj = nx.adjacency_matrix(G,sorted(G.nodes()))\n",
    "    \n",
    "    features = np.array(\n",
    "        [features for _, features in sorted(G.nodes(data='features'), key=lambda x: x[0])])\n",
    "    features = preprocess_features(features)\n",
    "    \n",
    "    # Skip train,valid,and test mask\n",
    "    \n",
    "    num_features = features.shape[1]\n",
    "    features = torch.FloatTensor(features)\n",
    "    return adj, features, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e6208b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, features, num_features = load_data(Content,Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00770463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edges(data):\n",
    "    set_random_seed(10) #Seed is randomly set\n",
    "    \n",
    "    # This select the edges that from<to\n",
    "    row, col = data.edge_index\n",
    "    mask = row < col\n",
    "    row, col = row[mask], col[mask]\n",
    "    \n",
    "    val_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "    \n",
    "    n_v = floor(val_ratio * row.size(0)).int() #number of validation positive edges\n",
    "    n_t = floor(test_ratio * row.size(0)).int() #number of test positive edges\n",
    "\n",
    "    #split positive edges   \n",
    "    perm = torch.randperm(row.size(0))\n",
    "    row, col = row[perm], col[perm]\n",
    "    r, c = row[:n_v], col[:n_v]\n",
    "    data.val_pos = torch.stack([r, c], dim=0)\n",
    "    r, c = row[n_v:n_v+n_t], col[n_v:n_v+n_t]\n",
    "    data.test_pos = torch.stack([r, c], dim=0)\n",
    "    r, c = row[n_v+n_t:], col[n_v+n_t:]\n",
    "    data.train_pos = torch.stack([r, c], dim=0)\n",
    "    print(data.train_pos.shape,data.test_pos.shape,data.val_pos.shape)\n",
    "    return\n",
    "    #sample negative edges\n",
    "    if args.practical_neg_sample == False:\n",
    "        # If practical_neg_sample == False, the sampled negative edges\n",
    "        # in the training and validation set aware the test set\n",
    "\n",
    "        neg_adj_mask = torch.ones(data.num_nodes, data.num_nodes, dtype=torch.uint8)\n",
    "        neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "        neg_adj_mask[row, col] = 0\n",
    "\n",
    "        # Sample all the negative edges and split into val, test, train negs\n",
    "        neg_row, neg_col = neg_adj_mask.nonzero(as_tuple=False).t()\n",
    "        perm = torch.randperm(neg_row.size(0))[:row.size(0)]\n",
    "        neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "        row, col = neg_row[:n_v], neg_col[:n_v]\n",
    "        data.val_neg = torch.stack([row, col], dim=0)\n",
    "\n",
    "        row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\n",
    "        data.test_neg = torch.stack([row, col], dim=0)\n",
    "\n",
    "        row, col = neg_row[n_v + n_t:], neg_col[n_v + n_t:]\n",
    "        data.train_neg = torch.stack([row, col], dim=0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        neg_adj_mask = torch.ones(data.num_nodes, data.num_nodes, dtype=torch.uint8)\n",
    "        neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "        neg_adj_mask[row, col] = 0\n",
    "\n",
    "        # Sample the test negative edges first\n",
    "        neg_row, neg_col = neg_adj_mask.nonzero(as_tuple=False).t()\n",
    "        perm = torch.randperm(neg_row.size(0))[:n_t]\n",
    "        neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "        data.test_neg = torch.stack([neg_row, neg_col], dim=0)\n",
    "\n",
    "        # Sample the train and val negative edges with only knowing \n",
    "        # the train positive edges\n",
    "        row, col = data.train_pos\n",
    "        neg_adj_mask = torch.ones(data.num_nodes, data.num_nodes, dtype=torch.uint8)\n",
    "        neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "        neg_adj_mask[row, col] = 0\n",
    "\n",
    "        # Sample the train and validation negative edges\n",
    "        neg_row, neg_col = neg_adj_mask.nonzero(as_tuple=False).t()\n",
    "\n",
    "        n_tot = n_v + data.train_pos.size(1)\n",
    "        perm = torch.randperm(neg_row.size(0))[:n_tot]\n",
    "        neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "        row, col = neg_row[:n_v], neg_col[:n_v]\n",
    "        data.val_neg = torch.stack([row, col], dim=0)\n",
    "\n",
    "        row, col = neg_row[n_v:], neg_col[n_v:]\n",
    "        data.train_neg = torch.stack([row, col], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d15223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "def prepare_data(content,train):\n",
    "    g, features, num_features = load_data(content,train)\n",
    "    A = g.toarray()\n",
    "    edge_index,_ = dense_to_sparse(torch.tensor(A))\n",
    "    print(A.shape)\n",
    "    data = Data(edge_index=edge_index,x=features.to(torch.float))\n",
    "    data = split_edges(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b627e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 2708)\n",
      "tensor([1, 2, 2, 3, 3, 3, 4, 4, 4, 4]) tensor([ 962,  527, 1937,  590,  839, 1086,  455, 1547, 1767, 2062])\n",
      "tensor(425, dtype=torch.int32) tensor(425, dtype=torch.int32) 4252\n",
      "torch.Size([2, 3402]) torch.Size([2, 425]) torch.Size([2, 425])\n"
     ]
    }
   ],
   "source": [
    "prepare_data(Content,Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b80d9b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E10311</td>\n",
       "      <td>2399</td>\n",
       "      <td>2339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E10255</td>\n",
       "      <td>2397</td>\n",
       "      <td>1144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E9395</td>\n",
       "      <td>872</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E5926</td>\n",
       "      <td>2450</td>\n",
       "      <td>1312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E5573</td>\n",
       "      <td>682</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8676</th>\n",
       "      <td>E1250</td>\n",
       "      <td>1481</td>\n",
       "      <td>611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677</th>\n",
       "      <td>E0</td>\n",
       "      <td>1685</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>E1204</td>\n",
       "      <td>2508</td>\n",
       "      <td>2278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681</th>\n",
       "      <td>E1171</td>\n",
       "      <td>1643</td>\n",
       "      <td>1383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>E4741</td>\n",
       "      <td>1879</td>\n",
       "      <td>1443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    to  from  label\n",
       "0     E10311  2399  2339      0\n",
       "1     E10255  2397  1144      1\n",
       "3      E9395   872   702      0\n",
       "4      E5926  2450  1312      1\n",
       "9      E5573   682   100      0\n",
       "...      ...   ...   ...    ...\n",
       "8676   E1250  1481   611      1\n",
       "8677      E0  1685  1150      1\n",
       "8680   E1204  2508  2278      1\n",
       "8681   E1171  1643  1383      0\n",
       "8682   E4741  1879  1443      1\n",
       "\n",
       "[4252 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[Train['from']<Train['to']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #load data from .mat or download from Planetoid dataset.\n",
    "    \n",
    "    if args.data_name in ('cora', 'citeseer', 'pubmed'):\n",
    "        data = load_Planetoid_data(args)\n",
    "        data = split_edges(data,args)\n",
    "    elif args.data_name in ('chameleon','squirrel','film','cornell','texas','wisconsin'):\n",
    "        datastr = args.data_name\n",
    "        split_index=str(0)## this split is node-classification split from geom-gcn, not for link prediction\n",
    "        splitstr = 'data/new_data_splits/'+datastr+'_split_0.6_0.2_'+split_index+'.npz'\n",
    "        g, features, labels, _, _, _, num_features, num_labels = new_load_data(datastr,splitstr)\n",
    "        A=g.toarray()\n",
    "        edge_index,_=dense_to_sparse(torch.tensor(A))\n",
    "        data=Data(edge_index=edge_index,x=features.to(torch.float))\n",
    "        data = split_edges(data,args)\n",
    "    else:\n",
    "        if args.use_splitted == True: #use splitted train/val/test\n",
    "            data = load_splitted_data(args)\n",
    "        else:\n",
    "            data = load_unsplitted_data(args)\n",
    "            data = split_edges(data,args)\n",
    "    \n",
    "    \n",
    "\n",
    "    set_random_seed(args.seed)\n",
    "    data_observed,feature_results= set_init_attribute_representation(data,args)\n",
    "\n",
    "    #Construct train, val and test data loader.\n",
    "    set_random_seed(args.seed)\n",
    "    train_graphs = []\n",
    "    val_graphs = []\n",
    "    test_graphs = []\n",
    "    for i in range(data.train_pos.size(1)):\n",
    "        train_graphs.append(minus_edge(data_observed,1,data.train_pos[:,i],args))\n",
    "\n",
    "    for i in range(data.train_neg.size(1)):\n",
    "        train_graphs.append(plus_edge(data_observed,0,data.train_neg[:,i],args))\n",
    "\n",
    "    for i in range(data.test_pos.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,1,data.test_pos[:,i],args))\n",
    "\n",
    "    for i in range(data.test_neg.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,0,data.test_neg[:,i],args))   \n",
    "    if args.observe_val_and_injection == False:\n",
    "        for i in range(data.val_pos.size(1)):\n",
    "            val_graphs.append(plus_edge(data_observed,1,data.val_pos[:,i],args))\n",
    "\n",
    "        for i in range(data.val_neg.size(1)):\n",
    "            val_graphs.append(plus_edge(data_observed,0,data.val_neg[:,i],args))\n",
    "    else:\n",
    "        for i in range(data.val_pos.size(1)):\n",
    "            val_graphs.append(minus_edge(data_observed,1,data.val_pos[:,i],args))\n",
    "\n",
    "        for i in range(data.val_neg.size(1)):\n",
    "            val_graphs.append(plus_edge(data_observed,0,data.val_neg[:,i],args))\n",
    "\n",
    "\n",
    "    \n",
    "    print('Train_link:', str(len(train_graphs)),' Val_link:',str(len(val_graphs)),' Test_link:',str(len(test_graphs)))\n",
    "\n",
    "    train_loader = DataLoader(train_graphs,batch_size=args.batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(val_graphs,batch_size=args.batch_size,shuffle=True)\n",
    "    test_loader = DataLoader(test_graphs,batch_size=args.batch_size,shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader,feature_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
