{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "789e6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Planetoid, Coauthor, Amazon\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GAE, VGAE, APPNP\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4081ad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model MODEL] [--dataset DATASET]\n",
      "                             [--epochs EPOCHS] [--channels CHANNELS]\n",
      "                             [--scaling_factor SCALING_FACTOR]\n",
      "                             [--training_rate TRAINING_RATE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\caleb\\AppData\\Roaming\\jupyter\\runtime\\kernel-e6d80757-d4f1-463e-8069-96629262bd82.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, default='VGNAE')\n",
    "parser.add_argument('--dataset', type=str, default='Cora')\n",
    "parser.add_argument('--epochs', type=int, default=300)\n",
    "parser.add_argument('--channels', type=int, default=128)\n",
    "parser.add_argument('--scaling_factor', type=float, default=1.8)\n",
    "parser.add_argument('--training_rate', type=float, default=0.8) \n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "552c97d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, LOSS: 10.9415, AUC: 0.6472, AP: 0.6925\n",
      "Epoch: 002, LOSS: 10.2842, AUC: 0.6504, AP: 0.6950\n",
      "Epoch: 003, LOSS: 10.6782, AUC: 0.6531, AP: 0.6971\n",
      "Epoch: 004, LOSS: 10.6574, AUC: 0.6551, AP: 0.6986\n",
      "Epoch: 005, LOSS: 10.6286, AUC: 0.6570, AP: 0.7001\n",
      "Epoch: 006, LOSS: 10.1641, AUC: 0.6590, AP: 0.7016\n",
      "Epoch: 007, LOSS: 10.0778, AUC: 0.6611, AP: 0.7031\n",
      "Epoch: 008, LOSS: 10.1770, AUC: 0.6631, AP: 0.7045\n",
      "Epoch: 009, LOSS: 10.1049, AUC: 0.6653, AP: 0.7061\n",
      "Epoch: 010, LOSS: 9.9055, AUC: 0.6677, AP: 0.7078\n",
      "Epoch: 011, LOSS: 9.7274, AUC: 0.6703, AP: 0.7096\n",
      "Epoch: 012, LOSS: 8.9727, AUC: 0.6730, AP: 0.7116\n",
      "Epoch: 013, LOSS: 8.9809, AUC: 0.6760, AP: 0.7139\n",
      "Epoch: 014, LOSS: 8.8456, AUC: 0.6793, AP: 0.7163\n",
      "Epoch: 015, LOSS: 8.6326, AUC: 0.6832, AP: 0.7192\n",
      "Epoch: 016, LOSS: 9.0088, AUC: 0.6876, AP: 0.7225\n",
      "Epoch: 017, LOSS: 8.7783, AUC: 0.6930, AP: 0.7265\n",
      "Epoch: 018, LOSS: 8.3972, AUC: 0.6993, AP: 0.7310\n",
      "Epoch: 019, LOSS: 8.4984, AUC: 0.7071, AP: 0.7369\n",
      "Epoch: 020, LOSS: 7.6068, AUC: 0.7165, AP: 0.7441\n",
      "Epoch: 021, LOSS: 7.7075, AUC: 0.7286, AP: 0.7538\n",
      "Epoch: 022, LOSS: 7.9317, AUC: 0.7441, AP: 0.7668\n",
      "Epoch: 023, LOSS: 7.5198, AUC: 0.7651, AP: 0.7847\n",
      "Epoch: 024, LOSS: 7.2378, AUC: 0.7910, AP: 0.8077\n",
      "Epoch: 025, LOSS: 7.4808, AUC: 0.8210, AP: 0.8350\n",
      "Epoch: 026, LOSS: 6.8328, AUC: 0.8531, AP: 0.8648\n",
      "Epoch: 027, LOSS: 6.5314, AUC: 0.8761, AP: 0.8858\n",
      "Epoch: 028, LOSS: 5.9514, AUC: 0.8846, AP: 0.8935\n",
      "Epoch: 029, LOSS: 5.9275, AUC: 0.8845, AP: 0.8938\n",
      "Epoch: 030, LOSS: 6.0308, AUC: 0.8797, AP: 0.8897\n",
      "Epoch: 031, LOSS: 5.8775, AUC: 0.8768, AP: 0.8870\n",
      "Epoch: 032, LOSS: 6.1078, AUC: 0.8766, AP: 0.8865\n",
      "Epoch: 033, LOSS: 5.8226, AUC: 0.8797, AP: 0.8891\n",
      "Epoch: 034, LOSS: 5.6863, AUC: 0.8849, AP: 0.8934\n",
      "Epoch: 035, LOSS: 5.7020, AUC: 0.8916, AP: 0.8989\n",
      "Epoch: 036, LOSS: 5.3432, AUC: 0.8969, AP: 0.9031\n",
      "Epoch: 037, LOSS: 5.1832, AUC: 0.8998, AP: 0.9054\n",
      "Epoch: 038, LOSS: 5.1669, AUC: 0.9015, AP: 0.9066\n",
      "Epoch: 039, LOSS: 5.0835, AUC: 0.9021, AP: 0.9068\n",
      "Epoch: 040, LOSS: 4.7905, AUC: 0.9023, AP: 0.9070\n",
      "Epoch: 041, LOSS: 4.7583, AUC: 0.9025, AP: 0.9072\n",
      "Epoch: 042, LOSS: 4.7042, AUC: 0.9029, AP: 0.9076\n",
      "Epoch: 043, LOSS: 4.6278, AUC: 0.9041, AP: 0.9087\n",
      "Epoch: 044, LOSS: 4.5846, AUC: 0.9062, AP: 0.9107\n",
      "Epoch: 045, LOSS: 4.5520, AUC: 0.9085, AP: 0.9127\n",
      "Epoch: 046, LOSS: 4.5951, AUC: 0.9108, AP: 0.9148\n",
      "Epoch: 047, LOSS: 4.2562, AUC: 0.9122, AP: 0.9161\n",
      "Epoch: 048, LOSS: 4.2318, AUC: 0.9125, AP: 0.9165\n",
      "Epoch: 049, LOSS: 4.4232, AUC: 0.9125, AP: 0.9165\n",
      "Epoch: 050, LOSS: 4.3249, AUC: 0.9122, AP: 0.9162\n",
      "Epoch: 051, LOSS: 3.8633, AUC: 0.9119, AP: 0.9158\n",
      "Epoch: 052, LOSS: 4.1002, AUC: 0.9120, AP: 0.9159\n",
      "Epoch: 053, LOSS: 3.9089, AUC: 0.9120, AP: 0.9157\n",
      "Epoch: 054, LOSS: 3.9337, AUC: 0.9121, AP: 0.9157\n",
      "Epoch: 055, LOSS: 4.1011, AUC: 0.9122, AP: 0.9156\n",
      "Epoch: 056, LOSS: 3.9749, AUC: 0.9120, AP: 0.9155\n",
      "Epoch: 057, LOSS: 3.7817, AUC: 0.9121, AP: 0.9154\n",
      "Epoch: 058, LOSS: 3.6804, AUC: 0.9122, AP: 0.9154\n",
      "Epoch: 059, LOSS: 3.7456, AUC: 0.9123, AP: 0.9155\n",
      "Epoch: 060, LOSS: 3.6089, AUC: 0.9123, AP: 0.9155\n",
      "Epoch: 061, LOSS: 3.4082, AUC: 0.9123, AP: 0.9155\n",
      "Epoch: 062, LOSS: 3.4588, AUC: 0.9123, AP: 0.9156\n",
      "Epoch: 063, LOSS: 3.5877, AUC: 0.9123, AP: 0.9156\n",
      "Epoch: 064, LOSS: 3.4562, AUC: 0.9126, AP: 0.9160\n",
      "Epoch: 065, LOSS: 3.4369, AUC: 0.9131, AP: 0.9164\n",
      "Epoch: 066, LOSS: 3.3965, AUC: 0.9136, AP: 0.9169\n",
      "Epoch: 067, LOSS: 3.2125, AUC: 0.9142, AP: 0.9173\n",
      "Epoch: 068, LOSS: 3.2829, AUC: 0.9147, AP: 0.9178\n",
      "Epoch: 069, LOSS: 3.2644, AUC: 0.9151, AP: 0.9181\n",
      "Epoch: 070, LOSS: 3.1615, AUC: 0.9153, AP: 0.9183\n",
      "Epoch: 071, LOSS: 3.2023, AUC: 0.9150, AP: 0.9181\n",
      "Epoch: 072, LOSS: 3.0433, AUC: 0.9145, AP: 0.9178\n",
      "Epoch: 073, LOSS: 3.0520, AUC: 0.9143, AP: 0.9177\n",
      "Epoch: 074, LOSS: 2.9133, AUC: 0.9139, AP: 0.9174\n",
      "Epoch: 075, LOSS: 2.8382, AUC: 0.9138, AP: 0.9173\n",
      "Epoch: 076, LOSS: 2.7581, AUC: 0.9139, AP: 0.9172\n",
      "Epoch: 077, LOSS: 2.9340, AUC: 0.9139, AP: 0.9172\n",
      "Epoch: 078, LOSS: 2.7960, AUC: 0.9140, AP: 0.9172\n",
      "Epoch: 079, LOSS: 2.8534, AUC: 0.9139, AP: 0.9172\n",
      "Epoch: 080, LOSS: 2.9207, AUC: 0.9137, AP: 0.9170\n",
      "Epoch: 081, LOSS: 2.8627, AUC: 0.9136, AP: 0.9168\n",
      "Epoch: 082, LOSS: 2.5659, AUC: 0.9135, AP: 0.9167\n",
      "Epoch: 083, LOSS: 2.8565, AUC: 0.9136, AP: 0.9167\n",
      "Epoch: 084, LOSS: 2.6478, AUC: 0.9142, AP: 0.9171\n",
      "Epoch: 085, LOSS: 2.5993, AUC: 0.9148, AP: 0.9175\n",
      "Epoch: 086, LOSS: 2.6920, AUC: 0.9153, AP: 0.9179\n",
      "Epoch: 087, LOSS: 2.6596, AUC: 0.9155, AP: 0.9181\n",
      "Epoch: 088, LOSS: 2.6419, AUC: 0.9154, AP: 0.9180\n",
      "Epoch: 089, LOSS: 2.6095, AUC: 0.9154, AP: 0.9180\n",
      "Epoch: 090, LOSS: 2.5938, AUC: 0.9153, AP: 0.9180\n",
      "Epoch: 091, LOSS: 2.5831, AUC: 0.9150, AP: 0.9179\n",
      "Epoch: 092, LOSS: 2.5188, AUC: 0.9148, AP: 0.9177\n",
      "Epoch: 093, LOSS: 2.4682, AUC: 0.9147, AP: 0.9177\n",
      "Epoch: 094, LOSS: 2.4250, AUC: 0.9148, AP: 0.9178\n",
      "Epoch: 095, LOSS: 2.4776, AUC: 0.9147, AP: 0.9178\n",
      "Epoch: 096, LOSS: 2.4366, AUC: 0.9148, AP: 0.9179\n",
      "Epoch: 097, LOSS: 2.3414, AUC: 0.9151, AP: 0.9180\n",
      "Epoch: 098, LOSS: 2.3330, AUC: 0.9153, AP: 0.9182\n",
      "Epoch: 099, LOSS: 2.4217, AUC: 0.9155, AP: 0.9183\n",
      "Epoch: 100, LOSS: 2.3073, AUC: 0.9156, AP: 0.9184\n",
      "Epoch: 101, LOSS: 2.3636, AUC: 0.9156, AP: 0.9183\n",
      "Epoch: 102, LOSS: 2.4010, AUC: 0.9154, AP: 0.9182\n",
      "Epoch: 103, LOSS: 2.2747, AUC: 0.9153, AP: 0.9180\n",
      "Epoch: 104, LOSS: 2.2329, AUC: 0.9152, AP: 0.9178\n",
      "Epoch: 105, LOSS: 2.2534, AUC: 0.9150, AP: 0.9175\n",
      "Epoch: 106, LOSS: 2.2954, AUC: 0.9147, AP: 0.9173\n",
      "Epoch: 107, LOSS: 2.2648, AUC: 0.9144, AP: 0.9170\n",
      "Epoch: 108, LOSS: 2.3360, AUC: 0.9143, AP: 0.9170\n",
      "Epoch: 109, LOSS: 2.1965, AUC: 0.9143, AP: 0.9171\n",
      "Epoch: 110, LOSS: 2.1311, AUC: 0.9143, AP: 0.9171\n",
      "Epoch: 111, LOSS: 2.1532, AUC: 0.9145, AP: 0.9173\n",
      "Epoch: 112, LOSS: 2.1290, AUC: 0.9146, AP: 0.9175\n",
      "Epoch: 113, LOSS: 2.1297, AUC: 0.9148, AP: 0.9177\n",
      "Epoch: 114, LOSS: 2.0420, AUC: 0.9149, AP: 0.9179\n",
      "Epoch: 115, LOSS: 2.1085, AUC: 0.9150, AP: 0.9180\n",
      "Epoch: 116, LOSS: 2.0967, AUC: 0.9151, AP: 0.9182\n",
      "Epoch: 117, LOSS: 2.0726, AUC: 0.9154, AP: 0.9184\n",
      "Epoch: 118, LOSS: 2.0430, AUC: 0.9155, AP: 0.9185\n",
      "Epoch: 119, LOSS: 2.1099, AUC: 0.9155, AP: 0.9184\n",
      "Epoch: 120, LOSS: 1.9603, AUC: 0.9158, AP: 0.9186\n",
      "Epoch: 121, LOSS: 1.9961, AUC: 0.9161, AP: 0.9188\n",
      "Epoch: 122, LOSS: 1.9211, AUC: 0.9162, AP: 0.9188\n",
      "Epoch: 123, LOSS: 2.0246, AUC: 0.9162, AP: 0.9188\n",
      "Epoch: 124, LOSS: 2.0346, AUC: 0.9162, AP: 0.9188\n",
      "Epoch: 125, LOSS: 1.9483, AUC: 0.9160, AP: 0.9187\n",
      "Epoch: 126, LOSS: 1.9048, AUC: 0.9157, AP: 0.9184\n",
      "Epoch: 127, LOSS: 2.0144, AUC: 0.9154, AP: 0.9183\n",
      "Epoch: 128, LOSS: 1.9276, AUC: 0.9152, AP: 0.9182\n",
      "Epoch: 129, LOSS: 1.9047, AUC: 0.9150, AP: 0.9181\n",
      "Epoch: 130, LOSS: 1.8736, AUC: 0.9150, AP: 0.9182\n",
      "Epoch: 131, LOSS: 1.9006, AUC: 0.9152, AP: 0.9183\n",
      "Epoch: 132, LOSS: 1.7403, AUC: 0.9154, AP: 0.9185\n",
      "Epoch: 133, LOSS: 1.8435, AUC: 0.9158, AP: 0.9188\n",
      "Epoch: 134, LOSS: 1.8506, AUC: 0.9161, AP: 0.9191\n",
      "Epoch: 135, LOSS: 1.9066, AUC: 0.9162, AP: 0.9192\n",
      "Epoch: 136, LOSS: 1.8384, AUC: 0.9162, AP: 0.9192\n",
      "Epoch: 137, LOSS: 1.8278, AUC: 0.9161, AP: 0.9191\n",
      "Epoch: 138, LOSS: 1.7701, AUC: 0.9157, AP: 0.9189\n",
      "Epoch: 139, LOSS: 1.7908, AUC: 0.9155, AP: 0.9188\n",
      "Epoch: 140, LOSS: 1.8185, AUC: 0.9152, AP: 0.9185\n",
      "Epoch: 141, LOSS: 1.7929, AUC: 0.9147, AP: 0.9182\n",
      "Epoch: 142, LOSS: 1.7655, AUC: 0.9145, AP: 0.9181\n",
      "Epoch: 143, LOSS: 1.7322, AUC: 0.9144, AP: 0.9180\n",
      "Epoch: 144, LOSS: 1.7366, AUC: 0.9143, AP: 0.9180\n",
      "Epoch: 145, LOSS: 1.6915, AUC: 0.9144, AP: 0.9181\n",
      "Epoch: 146, LOSS: 1.7474, AUC: 0.9145, AP: 0.9183\n",
      "Epoch: 147, LOSS: 1.6817, AUC: 0.9147, AP: 0.9185\n",
      "Epoch: 148, LOSS: 1.6835, AUC: 0.9150, AP: 0.9189\n",
      "Epoch: 149, LOSS: 1.7229, AUC: 0.9153, AP: 0.9192\n",
      "Epoch: 150, LOSS: 1.7289, AUC: 0.9157, AP: 0.9195\n",
      "Epoch: 151, LOSS: 1.7137, AUC: 0.9160, AP: 0.9198\n",
      "Epoch: 152, LOSS: 1.6386, AUC: 0.9163, AP: 0.9200\n",
      "Epoch: 153, LOSS: 1.6644, AUC: 0.9162, AP: 0.9199\n",
      "Epoch: 154, LOSS: 1.6620, AUC: 0.9161, AP: 0.9198\n",
      "Epoch: 155, LOSS: 1.6662, AUC: 0.9157, AP: 0.9195\n",
      "Epoch: 156, LOSS: 1.6715, AUC: 0.9152, AP: 0.9192\n",
      "Epoch: 157, LOSS: 1.7190, AUC: 0.9149, AP: 0.9190\n",
      "Epoch: 158, LOSS: 1.6249, AUC: 0.9147, AP: 0.9189\n",
      "Epoch: 159, LOSS: 1.6477, AUC: 0.9146, AP: 0.9188\n",
      "Epoch: 160, LOSS: 1.6925, AUC: 0.9146, AP: 0.9189\n",
      "Epoch: 161, LOSS: 1.6301, AUC: 0.9147, AP: 0.9190\n",
      "Epoch: 162, LOSS: 1.6197, AUC: 0.9149, AP: 0.9192\n",
      "Epoch: 163, LOSS: 1.5824, AUC: 0.9150, AP: 0.9194\n",
      "Epoch: 164, LOSS: 1.5292, AUC: 0.9153, AP: 0.9197\n",
      "Epoch: 165, LOSS: 1.5754, AUC: 0.9155, AP: 0.9198\n",
      "Epoch: 166, LOSS: 1.6048, AUC: 0.9155, AP: 0.9199\n",
      "Epoch: 167, LOSS: 1.6410, AUC: 0.9155, AP: 0.9199\n",
      "Epoch: 168, LOSS: 1.5887, AUC: 0.9153, AP: 0.9198\n",
      "Epoch: 169, LOSS: 1.5269, AUC: 0.9153, AP: 0.9197\n",
      "Epoch: 170, LOSS: 1.5444, AUC: 0.9153, AP: 0.9198\n",
      "Epoch: 171, LOSS: 1.5727, AUC: 0.9152, AP: 0.9197\n",
      "Epoch: 172, LOSS: 1.5601, AUC: 0.9152, AP: 0.9197\n",
      "Epoch: 173, LOSS: 1.5399, AUC: 0.9152, AP: 0.9197\n",
      "Epoch: 174, LOSS: 1.5280, AUC: 0.9153, AP: 0.9198\n",
      "Epoch: 175, LOSS: 1.5009, AUC: 0.9153, AP: 0.9199\n",
      "Epoch: 176, LOSS: 1.5509, AUC: 0.9152, AP: 0.9200\n",
      "Epoch: 177, LOSS: 1.4839, AUC: 0.9150, AP: 0.9200\n",
      "Epoch: 178, LOSS: 1.5550, AUC: 0.9147, AP: 0.9199\n",
      "Epoch: 179, LOSS: 1.5517, AUC: 0.9145, AP: 0.9198\n",
      "Epoch: 180, LOSS: 1.4502, AUC: 0.9144, AP: 0.9197\n",
      "Epoch: 181, LOSS: 1.5104, AUC: 0.9146, AP: 0.9199\n",
      "Epoch: 182, LOSS: 1.4742, AUC: 0.9149, AP: 0.9201\n",
      "Epoch: 183, LOSS: 1.4842, AUC: 0.9152, AP: 0.9203\n",
      "Epoch: 184, LOSS: 1.4577, AUC: 0.9156, AP: 0.9205\n",
      "Epoch: 185, LOSS: 1.4848, AUC: 0.9157, AP: 0.9206\n",
      "Epoch: 186, LOSS: 1.4296, AUC: 0.9157, AP: 0.9206\n",
      "Epoch: 187, LOSS: 1.4303, AUC: 0.9155, AP: 0.9205\n",
      "Epoch: 188, LOSS: 1.4922, AUC: 0.9153, AP: 0.9204\n",
      "Epoch: 189, LOSS: 1.4336, AUC: 0.9152, AP: 0.9203\n",
      "Epoch: 190, LOSS: 1.3770, AUC: 0.9151, AP: 0.9203\n",
      "Epoch: 191, LOSS: 1.4750, AUC: 0.9151, AP: 0.9203\n",
      "Epoch: 192, LOSS: 1.4968, AUC: 0.9148, AP: 0.9202\n",
      "Epoch: 193, LOSS: 1.4218, AUC: 0.9147, AP: 0.9202\n",
      "Epoch: 194, LOSS: 1.4514, AUC: 0.9148, AP: 0.9203\n",
      "Epoch: 195, LOSS: 1.4211, AUC: 0.9149, AP: 0.9203\n",
      "Epoch: 196, LOSS: 1.4236, AUC: 0.9148, AP: 0.9203\n",
      "Epoch: 197, LOSS: 1.4241, AUC: 0.9146, AP: 0.9202\n",
      "Epoch: 198, LOSS: 1.4017, AUC: 0.9146, AP: 0.9202\n",
      "Epoch: 199, LOSS: 1.4270, AUC: 0.9145, AP: 0.9202\n",
      "Epoch: 200, LOSS: 1.3678, AUC: 0.9145, AP: 0.9202\n",
      "Epoch: 201, LOSS: 1.3934, AUC: 0.9144, AP: 0.9201\n",
      "Epoch: 202, LOSS: 1.3909, AUC: 0.9144, AP: 0.9201\n",
      "Epoch: 203, LOSS: 1.4011, AUC: 0.9145, AP: 0.9202\n",
      "Epoch: 204, LOSS: 1.3761, AUC: 0.9145, AP: 0.9203\n",
      "Epoch: 205, LOSS: 1.3851, AUC: 0.9146, AP: 0.9204\n",
      "Epoch: 206, LOSS: 1.4233, AUC: 0.9146, AP: 0.9204\n",
      "Epoch: 207, LOSS: 1.3462, AUC: 0.9147, AP: 0.9205\n",
      "Epoch: 208, LOSS: 1.3781, AUC: 0.9148, AP: 0.9206\n",
      "Epoch: 209, LOSS: 1.3817, AUC: 0.9150, AP: 0.9208\n",
      "Epoch: 210, LOSS: 1.3988, AUC: 0.9151, AP: 0.9209\n",
      "Epoch: 211, LOSS: 1.3681, AUC: 0.9152, AP: 0.9210\n",
      "Epoch: 212, LOSS: 1.3472, AUC: 0.9152, AP: 0.9210\n",
      "Epoch: 213, LOSS: 1.3538, AUC: 0.9152, AP: 0.9210\n",
      "Epoch: 214, LOSS: 1.3551, AUC: 0.9150, AP: 0.9209\n",
      "Epoch: 215, LOSS: 1.3240, AUC: 0.9148, AP: 0.9208\n",
      "Epoch: 216, LOSS: 1.3373, AUC: 0.9145, AP: 0.9206\n",
      "Epoch: 217, LOSS: 1.3533, AUC: 0.9143, AP: 0.9205\n",
      "Epoch: 218, LOSS: 1.3254, AUC: 0.9141, AP: 0.9204\n",
      "Epoch: 219, LOSS: 1.3562, AUC: 0.9140, AP: 0.9204\n",
      "Epoch: 220, LOSS: 1.3212, AUC: 0.9141, AP: 0.9205\n",
      "Epoch: 221, LOSS: 1.3020, AUC: 0.9144, AP: 0.9207\n",
      "Epoch: 222, LOSS: 1.2961, AUC: 0.9145, AP: 0.9208\n",
      "Epoch: 223, LOSS: 1.2994, AUC: 0.9145, AP: 0.9208\n",
      "Epoch: 224, LOSS: 1.2867, AUC: 0.9146, AP: 0.9209\n",
      "Epoch: 225, LOSS: 1.2828, AUC: 0.9148, AP: 0.9211\n",
      "Epoch: 226, LOSS: 1.2968, AUC: 0.9148, AP: 0.9212\n",
      "Epoch: 227, LOSS: 1.2725, AUC: 0.9148, AP: 0.9212\n",
      "Epoch: 228, LOSS: 1.3491, AUC: 0.9147, AP: 0.9211\n",
      "Epoch: 229, LOSS: 1.3236, AUC: 0.9146, AP: 0.9211\n",
      "Epoch: 230, LOSS: 1.3583, AUC: 0.9143, AP: 0.9209\n",
      "Epoch: 231, LOSS: 1.3240, AUC: 0.9141, AP: 0.9207\n",
      "Epoch: 232, LOSS: 1.2544, AUC: 0.9139, AP: 0.9205\n",
      "Epoch: 233, LOSS: 1.2616, AUC: 0.9138, AP: 0.9205\n",
      "Epoch: 234, LOSS: 1.3245, AUC: 0.9138, AP: 0.9205\n",
      "Epoch: 235, LOSS: 1.2640, AUC: 0.9138, AP: 0.9206\n",
      "Epoch: 236, LOSS: 1.1812, AUC: 0.9138, AP: 0.9206\n",
      "Epoch: 237, LOSS: 1.2995, AUC: 0.9138, AP: 0.9206\n",
      "Epoch: 238, LOSS: 1.2431, AUC: 0.9138, AP: 0.9207\n",
      "Epoch: 239, LOSS: 1.2728, AUC: 0.9138, AP: 0.9208\n",
      "Epoch: 240, LOSS: 1.2375, AUC: 0.9139, AP: 0.9209\n",
      "Epoch: 241, LOSS: 1.2617, AUC: 0.9139, AP: 0.9209\n",
      "Epoch: 242, LOSS: 1.2892, AUC: 0.9139, AP: 0.9210\n",
      "Epoch: 243, LOSS: 1.2544, AUC: 0.9140, AP: 0.9211\n",
      "Epoch: 244, LOSS: 1.2658, AUC: 0.9140, AP: 0.9211\n",
      "Epoch: 245, LOSS: 1.2395, AUC: 0.9140, AP: 0.9211\n",
      "Epoch: 246, LOSS: 1.2603, AUC: 0.9140, AP: 0.9210\n",
      "Epoch: 247, LOSS: 1.2599, AUC: 0.9137, AP: 0.9209\n",
      "Epoch: 248, LOSS: 1.2318, AUC: 0.9134, AP: 0.9205\n",
      "Epoch: 249, LOSS: 1.2209, AUC: 0.9128, AP: 0.9201\n",
      "Epoch: 250, LOSS: 1.2318, AUC: 0.9123, AP: 0.9198\n",
      "Epoch: 251, LOSS: 1.2644, AUC: 0.9119, AP: 0.9197\n",
      "Epoch: 252, LOSS: 1.2538, AUC: 0.9118, AP: 0.9196\n",
      "Epoch: 253, LOSS: 1.2130, AUC: 0.9121, AP: 0.9199\n",
      "Epoch: 254, LOSS: 1.2374, AUC: 0.9125, AP: 0.9203\n",
      "Epoch: 255, LOSS: 1.2226, AUC: 0.9130, AP: 0.9207\n",
      "Epoch: 256, LOSS: 1.2471, AUC: 0.9133, AP: 0.9209\n",
      "Epoch: 257, LOSS: 1.2387, AUC: 0.9135, AP: 0.9210\n",
      "Epoch: 258, LOSS: 1.2339, AUC: 0.9135, AP: 0.9210\n",
      "Epoch: 259, LOSS: 1.2035, AUC: 0.9134, AP: 0.9210\n",
      "Epoch: 260, LOSS: 1.2057, AUC: 0.9134, AP: 0.9209\n",
      "Epoch: 261, LOSS: 1.2020, AUC: 0.9132, AP: 0.9208\n",
      "Epoch: 262, LOSS: 1.2204, AUC: 0.9130, AP: 0.9207\n",
      "Epoch: 263, LOSS: 1.2169, AUC: 0.9129, AP: 0.9206\n",
      "Epoch: 264, LOSS: 1.2225, AUC: 0.9127, AP: 0.9205\n",
      "Epoch: 265, LOSS: 1.2158, AUC: 0.9126, AP: 0.9205\n",
      "Epoch: 266, LOSS: 1.2194, AUC: 0.9125, AP: 0.9205\n",
      "Epoch: 267, LOSS: 1.1804, AUC: 0.9124, AP: 0.9205\n",
      "Epoch: 268, LOSS: 1.1849, AUC: 0.9124, AP: 0.9205\n",
      "Epoch: 269, LOSS: 1.1608, AUC: 0.9124, AP: 0.9205\n",
      "Epoch: 270, LOSS: 1.2003, AUC: 0.9123, AP: 0.9204\n",
      "Epoch: 271, LOSS: 1.1734, AUC: 0.9121, AP: 0.9203\n",
      "Epoch: 272, LOSS: 1.1509, AUC: 0.9117, AP: 0.9200\n",
      "Epoch: 273, LOSS: 1.2181, AUC: 0.9115, AP: 0.9199\n",
      "Epoch: 274, LOSS: 1.1823, AUC: 0.9115, AP: 0.9199\n",
      "Epoch: 275, LOSS: 1.1946, AUC: 0.9117, AP: 0.9201\n",
      "Epoch: 276, LOSS: 1.1350, AUC: 0.9120, AP: 0.9202\n",
      "Epoch: 277, LOSS: 1.1596, AUC: 0.9122, AP: 0.9204\n",
      "Epoch: 278, LOSS: 1.1818, AUC: 0.9122, AP: 0.9203\n",
      "Epoch: 279, LOSS: 1.1537, AUC: 0.9120, AP: 0.9202\n",
      "Epoch: 280, LOSS: 1.1741, AUC: 0.9118, AP: 0.9201\n",
      "Epoch: 281, LOSS: 1.1823, AUC: 0.9116, AP: 0.9200\n",
      "Epoch: 282, LOSS: 1.1767, AUC: 0.9114, AP: 0.9199\n",
      "Epoch: 283, LOSS: 1.1706, AUC: 0.9114, AP: 0.9200\n",
      "Epoch: 284, LOSS: 1.1626, AUC: 0.9114, AP: 0.9200\n",
      "Epoch: 285, LOSS: 1.1364, AUC: 0.9112, AP: 0.9198\n",
      "Epoch: 286, LOSS: 1.1298, AUC: 0.9109, AP: 0.9196\n",
      "Epoch: 287, LOSS: 1.1479, AUC: 0.9106, AP: 0.9194\n",
      "Epoch: 288, LOSS: 1.1466, AUC: 0.9103, AP: 0.9192\n",
      "Epoch: 289, LOSS: 1.1716, AUC: 0.9101, AP: 0.9191\n",
      "Epoch: 290, LOSS: 1.1435, AUC: 0.9099, AP: 0.9191\n",
      "Epoch: 291, LOSS: 1.1273, AUC: 0.9099, AP: 0.9191\n",
      "Epoch: 292, LOSS: 1.1058, AUC: 0.9101, AP: 0.9193\n",
      "Epoch: 293, LOSS: 1.1294, AUC: 0.9102, AP: 0.9193\n",
      "Epoch: 294, LOSS: 1.1730, AUC: 0.9102, AP: 0.9193\n",
      "Epoch: 295, LOSS: 1.1274, AUC: 0.9101, AP: 0.9193\n",
      "Epoch: 296, LOSS: 1.1200, AUC: 0.9101, AP: 0.9194\n",
      "Epoch: 297, LOSS: 1.1470, AUC: 0.9103, AP: 0.9196\n",
      "Epoch: 298, LOSS: 1.0857, AUC: 0.9106, AP: 0.9198\n",
      "Epoch: 299, LOSS: 1.1090, AUC: 0.9108, AP: 0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n",
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "!python main.py --dataset=Cora --training_rate=0.2 --epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dac4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5772ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "data = T.NormalizeFeatures()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d99ea2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used = 'VGNAE'\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, edge_index):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_channels, out_channels)\n",
    "        self.linear2 = nn.Linear(in_channels, out_channels)\n",
    "        self.propagate = APPNP(K=1, alpha=0)\n",
    "\n",
    "    def forward(self, x, edge_index,not_prop=0):\n",
    "        if model_used  == 'GNAE':\n",
    "            x = self.linear1(x)\n",
    "            x = F.normalize(x,p=2,dim=1)  * args.scaling_factor\n",
    "            x = self.propagate(x, edge_index)\n",
    "            return x\n",
    "\n",
    "        if model_used  == 'VGNAE':\n",
    "            x_ = self.linear1(x)\n",
    "            x_ = self.propagate(x_, edge_index)\n",
    "\n",
    "            x = self.linear2(x)\n",
    "            x = F.normalize(x,p=2,dim=1) * args.scaling_factor\n",
    "            x = self.propagate(x, edge_index)\n",
    "            return x, x_\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4af0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "channels = 128\n",
    "train_rate = 0.8\n",
    "val_ratio = (1-train_rate) / 3\n",
    "test_ratio = (1-train_rate) / 3 * 2\n",
    "data = train_test_split_edges(data.to(dev), val_ratio=val_ratio, test_ratio=test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c64ccaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(data.x.size()[0])\n",
    "if model_used  == 'GNAE':   \n",
    "    model = GAE(Encoder(data.x.size()[1], channels, data.train_pos_edge_index)).to(dev)\n",
    "if model_used  == 'VGNAE':\n",
    "    model = VGAE(Encoder(data.x.size()[1], channels, data.train_pos_edge_index)).to(dev)\n",
    "\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1525cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z  = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    if model_used  in ['VGAE']:\n",
    "        loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c5d4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pos_edge_index, neg_edge_index, plot_his=0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "edec398f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19112\\3792536311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19112\\3052696038.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mz\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecon_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pos_edge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_used\u001b[0m  \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'VGAE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\nn\\models\\autoencoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;34m\"\"\"\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mu__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_LOGSTD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mu__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__logstd__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19112\\1530283672.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, not_prop)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaling_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for epoch in range(1,epochs):\n",
    "    loss = train()\n",
    "    loss = float(loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pos, test_neg = data.test_pos_edge_index, data.test_neg_edge_index\n",
    "        auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "        print('Epoch: {:03d}, LOSS: {:.4f}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, loss, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cac3051",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19112\\2101036981.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Split the graph into training and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_pos_edge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pos_edge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Create a new Data object with the positive edges only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     11\u001b[0m                 f', {details}' if details is not None else '')\n\u001b[0;32m     12\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\utils\\train_test_split_edges.py\u001b[0m in \u001b[0;36mtrain_test_split_edges\u001b[1;34m(data, val_ratio, test_ratio)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[1;34m'batch'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m  \u001b[1;31m# No batch-mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mnum_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import VGAE\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Split the graph into training and test sets\n",
    "train_pos_edge_index, test_pos_edge_index = train_test_split_edges(data.edge_index)\n",
    "\n",
    "# Create a new Data object with the positive edges only\n",
    "train_data = data.clone()\n",
    "train_data.edge_index = train_pos_edge_index\n",
    "\n",
    "# Define VGAE model and optimizer\n",
    "model = VGAE(data.num_features, 16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    adj_recon = model.decode(z, train_data.edge_index)\n",
    "    loss = F.binary_cross_entropy(adj_recon.view(-1), train_data.adjacency_matrix().view(-1))\n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "epochs = 300\n",
    "for epoch in range(1,epochs):\n",
    "    loss = train()\n",
    "    loss = float(loss)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "z = model.encode(data.x, data.edge_index)\n",
    "test_pred = (z[test_pos_edge_index[0]] * z[test_pos_edge_index[1]]).sum(dim=1)\n",
    "test_true = torch.ones_like(test_pred)\n",
    "test_ap = sklearn.metrics.average_precision_score(test_true, test_pred.detach().numpy())\n",
    "test_auc = sklearn.metrics.roc_auc_score(test_true, test_pred.detach().numpy())\n",
    "\n",
    "print(f\"Test AP: {test_ap:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3fbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
