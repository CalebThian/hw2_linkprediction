{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0811582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Planetoid, Coauthor, Amazon\n",
    "from torch_geometric.utils import train_test_split_edges, dense_to_sparse\n",
    "from torch_geometric.nn import GAE, VGAE, APPNP\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36680c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e9ed1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "data = T.NormalizeFeatures()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75ec8b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E370</td>\n",
       "      <td>26</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E667</td>\n",
       "      <td>196</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3190</td>\n",
       "      <td>739</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E848</td>\n",
       "      <td>576</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2161</td>\n",
       "      <td>466</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   to  from\n",
       "0   E370   26   317\n",
       "1   E667  196   323\n",
       "2  E3190  739   468\n",
       "3   E848  576   156\n",
       "4  E2161  466   199"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"hw2_data/\"\n",
    "dss = ['dataset1','dataset2','dataset3'] #datasets\n",
    "datasets = dict()\n",
    "for ds in dss:\n",
    "    datasets[ds] = dict()\n",
    "    datasets[ds]['content'] = pd.read_csv(path+ds+\"/content.csv\",delimiter = '\\t',header = None)\n",
    "    datasets[ds]['train'] = pd.read_csv(path+ds+\"/train.csv\",delimiter = ',')\n",
    "    datasets[ds]['test'] = pd.read_csv(path+ds+\"/test.csv\",delimiter = ',')\n",
    "    datasets[ds]['upload'] = pd.read_csv(path+ds+\"/upload.csv\",delimiter = ',')\n",
    "datasets[dss[2]]['test'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72a1e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example:\n",
    "dss_num = 2\n",
    "Content = datasets[dss[dss_num]]['content']\n",
    "Train = datasets[dss[dss_num]]['train']\n",
    "Test = datasets[dss[dss_num]]['test']\n",
    "Upload = datasets[dss[dss_num]]['upload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8855569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(content,train, test):\n",
    "    G = nx.DiGraph()\n",
    "    # for easier split the edges, create 2 graph, 1 with positive edge, the other with given negative edges\n",
    "    G_pos = nx.DiGraph()\n",
    "    G_neg = nx.DiGraph()\n",
    "    graph_node_features_dict = dict()\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        #graph_node_features_dict[content.iloc[i,0]] = np.array(content.iloc[i,1:])\n",
    "        G.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        # pos and neg\n",
    "        G_pos.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        G_neg.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        \n",
    "    for i in range(len(train)):\n",
    "        # Adding nodes into G\n",
    "        '''\n",
    "        if train.loc[i,'from'] not in G:\n",
    "            G.add_node(train.loc[i,'from'],features = graph_node_features_dict[train.loc[i,'from']])\n",
    "        if train.loc[i,'to'] not in G:\n",
    "            G.add_node(train.loc[i,'to'],features = graph_node_features_dict[train.loc[i,'to']])\n",
    "        ''' \n",
    "        # Adding edges\n",
    "        G.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "        \n",
    "        # pos and neg\n",
    "        if train.loc[i,'label'] == 0: \n",
    "            G_neg.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "        else:\n",
    "            G_pos.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "\n",
    "    adj = nx.adjacency_matrix(G,sorted(G.nodes()))\n",
    "    adj_pos = nx.adjacency_matrix(G_pos,sorted(G_pos.nodes()))\n",
    "    adj_neg = nx.adjacency_matrix(G_neg,sorted(G_neg.nodes()))\n",
    "    features = np.array(\n",
    "        [features for _, features in sorted(G.nodes(data='features'), key=lambda x: x[0])])\n",
    "    \n",
    "    # Skip train,valid,and test mask\n",
    "    \n",
    "    num_features = features.shape[1]\n",
    "    features = torch.FloatTensor(features)\n",
    "    return adj, adj_pos, adj_neg, features, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9591065a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[877, 1703], edge_index=[2, 1273], test=[2, 644])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, pos, neg, features, num_features = load_data(Content,Train,Test)\n",
    "A = g.toarray()\n",
    "edge_index,_ = dense_to_sparse(torch.tensor(A))\n",
    "Apos = pos.toarray()\n",
    "edge_index_pos,_ = dense_to_sparse(torch.tensor(Apos))\n",
    "Aneg = neg.toarray()\n",
    "edge_index_neg,_ = dense_to_sparse(torch.tensor(Aneg))\n",
    "data = Data(edge_index=edge_index_pos,x=features.to(torch.float),test = torch.tensor([Test['from'],Test['to']]))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd5c7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "channels = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e67c311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[877, 1703], test=[2, 644], val_pos_edge_index=[2, 55], test_pos_edge_index=[2, 0], train_pos_edge_index=[2, 1006], train_neg_adj_mask=[877, 877], val_neg_edge_index=[2, 55], test_neg_edge_index=[2, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rate = 0.95\n",
    "val_ratio = (1-train_rate)#/3\n",
    "test_ratio = 0#(1-train_rate) / 3 * 2\n",
    "data = train_test_split_edges(data.to(dev), val_ratio=val_ratio, test_ratio=0)\n",
    "               #,train_pos_edge_index = edge_index_pos,neg = edge_index_neg,test = edge_index_test)\n",
    "data = T.NormalizeFeatures()(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79d10b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_used = 'VGNAE'\n",
    "scaling_factor = 1.8\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, edge_index):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_channels, out_channels)\n",
    "        self.linear2 = nn.Linear(in_channels, out_channels)\n",
    "        self.propagate = APPNP(K=1, alpha=0)\n",
    "\n",
    "    def forward(self, x, edge_index,not_prop=0):\n",
    "        if model_used  == 'GNAE':\n",
    "            x = self.linear1(x)\n",
    "            x = F.normalize(x,p=2,dim=1)  * scaling_factor\n",
    "            x = self.propagate(x, edge_index)\n",
    "            return x\n",
    "\n",
    "        if model_used  == 'VGNAE':\n",
    "            x_ = self.linear1(x)\n",
    "            x_ = self.propagate(x_, edge_index)\n",
    "\n",
    "            x = self.linear2(x)\n",
    "            x = F.normalize(x,p=2,dim=1) * scaling_factor\n",
    "            x = self.propagate(x, edge_index)\n",
    "            return x, x_\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b8f0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z  = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    if model_used  in ['VGNAE']:\n",
    "        loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f468ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2332a3db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = int(data.x.size()[0])\n",
    "if model_used  == 'GNAE':   \n",
    "    model = GAE(Encoder(data.x.size()[1], channels, data.train_pos_edge_index)).to(dev)\n",
    "if model_used  == 'VGNAE':\n",
    "    model = VGAE(Encoder(data.x.size()[1], channels, data.train_pos_edge_index)).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "222e977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7d10ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7282644628099174, 0.7760739585717037)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(data.val_pos_edge_index, data.val_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba56ab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, LOSS: 14.3380, AUC: 0.7210, AP: 0.7716\n",
      "Epoch: 002, LOSS: 14.2239, AUC: 0.7193, AP: 0.7704\n",
      "Epoch: 003, LOSS: 13.0865, AUC: 0.7203, AP: 0.7715\n",
      "Epoch: 004, LOSS: 13.9011, AUC: 0.7200, AP: 0.7709\n",
      "Epoch: 005, LOSS: 14.1405, AUC: 0.7210, AP: 0.7721\n",
      "Epoch: 006, LOSS: 12.2154, AUC: 0.7213, AP: 0.7724\n",
      "Epoch: 007, LOSS: 13.0210, AUC: 0.7223, AP: 0.7731\n",
      "Epoch: 008, LOSS: 13.7097, AUC: 0.7217, AP: 0.7719\n",
      "Epoch: 009, LOSS: 13.6891, AUC: 0.7213, AP: 0.7716\n",
      "Epoch: 010, LOSS: 13.8397, AUC: 0.7217, AP: 0.7723\n",
      "Epoch: 011, LOSS: 13.0581, AUC: 0.7217, AP: 0.7723\n",
      "Epoch: 012, LOSS: 12.9522, AUC: 0.7220, AP: 0.7725\n",
      "Epoch: 013, LOSS: 12.4356, AUC: 0.7220, AP: 0.7724\n",
      "Epoch: 014, LOSS: 12.9357, AUC: 0.7226, AP: 0.7727\n",
      "Epoch: 015, LOSS: 12.4387, AUC: 0.7226, AP: 0.7727\n",
      "Epoch: 016, LOSS: 12.4696, AUC: 0.7233, AP: 0.7730\n",
      "Epoch: 017, LOSS: 12.2219, AUC: 0.7236, AP: 0.7733\n",
      "Epoch: 018, LOSS: 12.2491, AUC: 0.7236, AP: 0.7733\n",
      "Epoch: 019, LOSS: 12.9630, AUC: 0.7240, AP: 0.7742\n",
      "Epoch: 020, LOSS: 11.7637, AUC: 0.7236, AP: 0.7741\n",
      "Epoch: 021, LOSS: 11.3635, AUC: 0.7236, AP: 0.7741\n",
      "Epoch: 022, LOSS: 11.1268, AUC: 0.7236, AP: 0.7741\n",
      "Epoch: 023, LOSS: 10.8536, AUC: 0.7233, AP: 0.7739\n",
      "Epoch: 024, LOSS: 11.5612, AUC: 0.7233, AP: 0.7739\n",
      "Epoch: 025, LOSS: 11.2110, AUC: 0.7233, AP: 0.7739\n",
      "Epoch: 026, LOSS: 12.0244, AUC: 0.7233, AP: 0.7739\n",
      "Epoch: 027, LOSS: 11.5824, AUC: 0.7236, AP: 0.7741\n",
      "Epoch: 028, LOSS: 10.2961, AUC: 0.7236, AP: 0.7741\n",
      "Epoch: 029, LOSS: 11.3762, AUC: 0.7230, AP: 0.7736\n",
      "Epoch: 030, LOSS: 10.6467, AUC: 0.7230, AP: 0.7736\n",
      "Epoch: 031, LOSS: 10.6610, AUC: 0.7233, AP: 0.7738\n",
      "Epoch: 032, LOSS: 10.8241, AUC: 0.7233, AP: 0.7738\n",
      "Epoch: 033, LOSS: 10.5015, AUC: 0.7233, AP: 0.7738\n",
      "Epoch: 034, LOSS: 10.1753, AUC: 0.7233, AP: 0.7738\n",
      "Epoch: 035, LOSS: 10.4727, AUC: 0.7236, AP: 0.7739\n",
      "Epoch: 036, LOSS: 10.1047, AUC: 0.7240, AP: 0.7740\n",
      "Epoch: 037, LOSS: 10.5878, AUC: 0.7243, AP: 0.7743\n",
      "Epoch: 038, LOSS: 10.5825, AUC: 0.7246, AP: 0.7744\n",
      "Epoch: 039, LOSS: 9.9848, AUC: 0.7246, AP: 0.7744\n",
      "Epoch: 040, LOSS: 9.5930, AUC: 0.7250, AP: 0.7746\n",
      "Epoch: 041, LOSS: 9.7887, AUC: 0.7256, AP: 0.7751\n",
      "Epoch: 042, LOSS: 9.3933, AUC: 0.7263, AP: 0.7754\n",
      "Epoch: 043, LOSS: 9.3264, AUC: 0.7276, AP: 0.7760\n",
      "Epoch: 044, LOSS: 9.1914, AUC: 0.7286, AP: 0.7764\n",
      "Epoch: 045, LOSS: 10.2502, AUC: 0.7289, AP: 0.7766\n",
      "Epoch: 046, LOSS: 9.6478, AUC: 0.7286, AP: 0.7765\n",
      "Epoch: 047, LOSS: 9.2808, AUC: 0.7286, AP: 0.7765\n",
      "Epoch: 048, LOSS: 9.3732, AUC: 0.7286, AP: 0.7765\n",
      "Epoch: 049, LOSS: 9.3840, AUC: 0.7286, AP: 0.7765\n",
      "Epoch: 050, LOSS: 9.8710, AUC: 0.7289, AP: 0.7776\n",
      "Epoch: 051, LOSS: 8.8052, AUC: 0.7293, AP: 0.7787\n",
      "Epoch: 052, LOSS: 8.3256, AUC: 0.7289, AP: 0.7786\n",
      "Epoch: 053, LOSS: 8.5736, AUC: 0.7289, AP: 0.7786\n",
      "Epoch: 054, LOSS: 9.0344, AUC: 0.7289, AP: 0.7786\n",
      "Epoch: 055, LOSS: 8.8209, AUC: 0.7286, AP: 0.7784\n",
      "Epoch: 056, LOSS: 8.2709, AUC: 0.7286, AP: 0.7784\n",
      "Epoch: 057, LOSS: 7.9655, AUC: 0.7283, AP: 0.7783\n",
      "Epoch: 058, LOSS: 8.6647, AUC: 0.7286, AP: 0.7785\n",
      "Epoch: 059, LOSS: 7.7613, AUC: 0.7293, AP: 0.7793\n",
      "Epoch: 060, LOSS: 8.0686, AUC: 0.7286, AP: 0.7788\n",
      "Epoch: 061, LOSS: 8.0477, AUC: 0.7293, AP: 0.7797\n",
      "Epoch: 062, LOSS: 7.9147, AUC: 0.7296, AP: 0.7800\n",
      "Epoch: 063, LOSS: 8.1916, AUC: 0.7296, AP: 0.7800\n",
      "Epoch: 064, LOSS: 8.2261, AUC: 0.7306, AP: 0.7805\n",
      "Epoch: 065, LOSS: 7.4424, AUC: 0.7319, AP: 0.7817\n",
      "Epoch: 066, LOSS: 7.9149, AUC: 0.7319, AP: 0.7817\n",
      "Epoch: 067, LOSS: 7.7259, AUC: 0.7322, AP: 0.7819\n",
      "Epoch: 068, LOSS: 7.7526, AUC: 0.7336, AP: 0.7827\n",
      "Epoch: 069, LOSS: 7.8174, AUC: 0.7336, AP: 0.7827\n",
      "Epoch: 070, LOSS: 7.8405, AUC: 0.7342, AP: 0.7831\n",
      "Epoch: 071, LOSS: 7.9756, AUC: 0.7342, AP: 0.7831\n",
      "Epoch: 072, LOSS: 7.7098, AUC: 0.7339, AP: 0.7829\n",
      "Epoch: 073, LOSS: 7.7500, AUC: 0.7339, AP: 0.7829\n",
      "Epoch: 074, LOSS: 7.0625, AUC: 0.7342, AP: 0.7833\n",
      "Epoch: 075, LOSS: 7.2704, AUC: 0.7345, AP: 0.7834\n",
      "Epoch: 076, LOSS: 7.3913, AUC: 0.7349, AP: 0.7836\n",
      "Epoch: 077, LOSS: 6.7672, AUC: 0.7352, AP: 0.7835\n",
      "Epoch: 078, LOSS: 7.0112, AUC: 0.7355, AP: 0.7838\n",
      "Epoch: 079, LOSS: 7.4962, AUC: 0.7355, AP: 0.7838\n",
      "Epoch: 080, LOSS: 6.6902, AUC: 0.7355, AP: 0.7838\n",
      "Epoch: 081, LOSS: 6.6813, AUC: 0.7359, AP: 0.7844\n",
      "Epoch: 082, LOSS: 6.9918, AUC: 0.7362, AP: 0.7845\n",
      "Epoch: 083, LOSS: 7.3357, AUC: 0.7365, AP: 0.7850\n",
      "Epoch: 084, LOSS: 7.2509, AUC: 0.7375, AP: 0.7856\n",
      "Epoch: 085, LOSS: 6.8594, AUC: 0.7379, AP: 0.7858\n",
      "Epoch: 086, LOSS: 6.6915, AUC: 0.7385, AP: 0.7862\n",
      "Epoch: 087, LOSS: 6.6692, AUC: 0.7385, AP: 0.7860\n",
      "Epoch: 088, LOSS: 6.8350, AUC: 0.7382, AP: 0.7858\n",
      "Epoch: 089, LOSS: 6.4090, AUC: 0.7385, AP: 0.7860\n",
      "Epoch: 090, LOSS: 6.6548, AUC: 0.7388, AP: 0.7861\n",
      "Epoch: 091, LOSS: 6.3239, AUC: 0.7385, AP: 0.7858\n",
      "Epoch: 092, LOSS: 6.8023, AUC: 0.7402, AP: 0.7866\n",
      "Epoch: 093, LOSS: 6.1946, AUC: 0.7425, AP: 0.7879\n",
      "Epoch: 094, LOSS: 6.3080, AUC: 0.7428, AP: 0.7880\n",
      "Epoch: 095, LOSS: 6.4974, AUC: 0.7451, AP: 0.7896\n",
      "Epoch: 096, LOSS: 6.3408, AUC: 0.7468, AP: 0.7918\n",
      "Epoch: 097, LOSS: 5.8836, AUC: 0.7478, AP: 0.7922\n",
      "Epoch: 098, LOSS: 5.8833, AUC: 0.7491, AP: 0.7937\n",
      "Epoch: 099, LOSS: 5.6695, AUC: 0.7507, AP: 0.7950\n",
      "Epoch: 100, LOSS: 5.7582, AUC: 0.7514, AP: 0.7954\n",
      "Epoch: 101, LOSS: 6.0645, AUC: 0.7514, AP: 0.7954\n",
      "Epoch: 102, LOSS: 6.0948, AUC: 0.7524, AP: 0.7964\n",
      "Epoch: 103, LOSS: 5.8692, AUC: 0.7540, AP: 0.7973\n",
      "Epoch: 104, LOSS: 5.9753, AUC: 0.7554, AP: 0.7985\n",
      "Epoch: 105, LOSS: 6.1659, AUC: 0.7574, AP: 0.8001\n",
      "Epoch: 106, LOSS: 6.0842, AUC: 0.7587, AP: 0.8010\n",
      "Epoch: 107, LOSS: 6.3132, AUC: 0.7626, AP: 0.8038\n",
      "Epoch: 108, LOSS: 5.4163, AUC: 0.7646, AP: 0.8050\n",
      "Epoch: 109, LOSS: 5.2778, AUC: 0.7679, AP: 0.8068\n",
      "Epoch: 110, LOSS: 5.6620, AUC: 0.7709, AP: 0.8087\n",
      "Epoch: 111, LOSS: 5.4430, AUC: 0.7726, AP: 0.8093\n",
      "Epoch: 112, LOSS: 5.3012, AUC: 0.7739, AP: 0.8105\n",
      "Epoch: 113, LOSS: 5.5374, AUC: 0.7785, AP: 0.8138\n",
      "Epoch: 114, LOSS: 5.5779, AUC: 0.7798, AP: 0.8143\n",
      "Epoch: 115, LOSS: 5.5962, AUC: 0.7855, AP: 0.8195\n",
      "Epoch: 116, LOSS: 5.1475, AUC: 0.7931, AP: 0.8259\n",
      "Epoch: 117, LOSS: 5.0395, AUC: 0.8007, AP: 0.8317\n",
      "Epoch: 118, LOSS: 5.0374, AUC: 0.8076, AP: 0.8364\n",
      "Epoch: 119, LOSS: 5.5357, AUC: 0.8145, AP: 0.8417\n",
      "Epoch: 120, LOSS: 4.8838, AUC: 0.8218, AP: 0.8479\n",
      "Epoch: 121, LOSS: 4.5745, AUC: 0.8278, AP: 0.8518\n",
      "Epoch: 122, LOSS: 5.0346, AUC: 0.8436, AP: 0.8646\n",
      "Epoch: 123, LOSS: 4.6743, AUC: 0.8569, AP: 0.8747\n",
      "Epoch: 124, LOSS: 4.9190, AUC: 0.8704, AP: 0.8841\n",
      "Epoch: 125, LOSS: 4.4926, AUC: 0.8777, AP: 0.8886\n",
      "Epoch: 126, LOSS: 4.0735, AUC: 0.8836, AP: 0.8926\n",
      "Epoch: 127, LOSS: 4.0467, AUC: 0.8873, AP: 0.8992\n",
      "Epoch: 128, LOSS: 3.8336, AUC: 0.8922, AP: 0.9045\n",
      "Epoch: 129, LOSS: 4.0761, AUC: 0.8919, AP: 0.9033\n",
      "Epoch: 130, LOSS: 3.9224, AUC: 0.8926, AP: 0.9024\n",
      "Epoch: 131, LOSS: 3.4841, AUC: 0.8936, AP: 0.9034\n",
      "Epoch: 132, LOSS: 3.9897, AUC: 0.8912, AP: 0.9020\n",
      "Epoch: 133, LOSS: 4.0081, AUC: 0.8912, AP: 0.9018\n",
      "Epoch: 134, LOSS: 3.9359, AUC: 0.8912, AP: 0.9007\n",
      "Epoch: 135, LOSS: 4.0328, AUC: 0.8936, AP: 0.9031\n",
      "Epoch: 136, LOSS: 3.9970, AUC: 0.8942, AP: 0.9034\n",
      "Epoch: 137, LOSS: 3.9868, AUC: 0.8936, AP: 0.9030\n",
      "Epoch: 138, LOSS: 3.9514, AUC: 0.8932, AP: 0.9017\n",
      "Epoch: 139, LOSS: 3.8472, AUC: 0.8939, AP: 0.9015\n",
      "Epoch: 140, LOSS: 3.4837, AUC: 0.8945, AP: 0.9030\n",
      "Epoch: 141, LOSS: 3.4174, AUC: 0.8959, AP: 0.9044\n",
      "Epoch: 142, LOSS: 3.2513, AUC: 0.8959, AP: 0.9043\n",
      "Epoch: 143, LOSS: 3.3764, AUC: 0.8942, AP: 0.9024\n",
      "Epoch: 144, LOSS: 3.6089, AUC: 0.8939, AP: 0.9021\n",
      "Epoch: 145, LOSS: 3.4376, AUC: 0.8945, AP: 0.9029\n",
      "Epoch: 146, LOSS: 3.4276, AUC: 0.8955, AP: 0.9033\n",
      "Epoch: 147, LOSS: 3.2838, AUC: 0.8959, AP: 0.9034\n",
      "Epoch: 148, LOSS: 3.3963, AUC: 0.8952, AP: 0.9027\n",
      "Epoch: 149, LOSS: 3.4567, AUC: 0.8942, AP: 0.9009\n",
      "Epoch: 150, LOSS: 3.3699, AUC: 0.8936, AP: 0.9001\n",
      "Epoch: 151, LOSS: 3.3471, AUC: 0.8926, AP: 0.8991\n",
      "Epoch: 152, LOSS: 3.0688, AUC: 0.8922, AP: 0.8971\n",
      "Epoch: 153, LOSS: 3.1078, AUC: 0.8936, AP: 0.8978\n",
      "Epoch: 154, LOSS: 3.4163, AUC: 0.8936, AP: 0.8972\n",
      "Epoch: 155, LOSS: 3.1633, AUC: 0.8949, AP: 0.8986\n",
      "Epoch: 156, LOSS: 3.1790, AUC: 0.8949, AP: 0.8985\n",
      "Epoch: 157, LOSS: 3.1655, AUC: 0.8955, AP: 0.8982\n",
      "Epoch: 158, LOSS: 3.2678, AUC: 0.8965, AP: 0.8987\n",
      "Epoch: 159, LOSS: 2.9391, AUC: 0.8955, AP: 0.8977\n",
      "Epoch: 160, LOSS: 2.9628, AUC: 0.8949, AP: 0.8969\n",
      "Epoch: 161, LOSS: 3.0348, AUC: 0.8949, AP: 0.8964\n",
      "Epoch: 162, LOSS: 3.2172, AUC: 0.8952, AP: 0.8967\n",
      "Epoch: 163, LOSS: 2.8408, AUC: 0.8945, AP: 0.8959\n",
      "Epoch: 164, LOSS: 2.9121, AUC: 0.8945, AP: 0.8953\n",
      "Epoch: 165, LOSS: 3.0266, AUC: 0.8942, AP: 0.8949\n",
      "Epoch: 166, LOSS: 2.7554, AUC: 0.8945, AP: 0.8953\n",
      "Epoch: 167, LOSS: 2.9707, AUC: 0.8949, AP: 0.8954\n",
      "Epoch: 168, LOSS: 2.9341, AUC: 0.8952, AP: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 169, LOSS: 2.9675, AUC: 0.8959, AP: 0.8963\n",
      "Epoch: 170, LOSS: 3.0992, AUC: 0.8979, AP: 0.8982\n",
      "Epoch: 171, LOSS: 3.0374, AUC: 0.8985, AP: 0.9001\n",
      "Epoch: 172, LOSS: 2.6964, AUC: 0.8995, AP: 0.9012\n",
      "Epoch: 173, LOSS: 2.9711, AUC: 0.9012, AP: 0.9030\n",
      "Epoch: 174, LOSS: 3.0357, AUC: 0.9028, AP: 0.9047\n",
      "Epoch: 175, LOSS: 2.9239, AUC: 0.9025, AP: 0.9049\n",
      "Epoch: 176, LOSS: 2.7794, AUC: 0.9038, AP: 0.9060\n",
      "Epoch: 177, LOSS: 2.7279, AUC: 0.9048, AP: 0.9072\n",
      "Epoch: 178, LOSS: 2.8323, AUC: 0.9045, AP: 0.9071\n",
      "Epoch: 179, LOSS: 2.6761, AUC: 0.9051, AP: 0.9073\n",
      "Epoch: 180, LOSS: 2.6304, AUC: 0.9058, AP: 0.9078\n",
      "Epoch: 181, LOSS: 2.6583, AUC: 0.9081, AP: 0.9092\n",
      "Epoch: 182, LOSS: 2.8543, AUC: 0.9071, AP: 0.9070\n",
      "Epoch: 183, LOSS: 2.8164, AUC: 0.9078, AP: 0.9075\n",
      "Epoch: 184, LOSS: 2.7431, AUC: 0.9081, AP: 0.9082\n",
      "Epoch: 185, LOSS: 2.5536, AUC: 0.9088, AP: 0.9092\n",
      "Epoch: 186, LOSS: 2.5534, AUC: 0.9084, AP: 0.9086\n",
      "Epoch: 187, LOSS: 2.6790, AUC: 0.9084, AP: 0.9088\n",
      "Epoch: 188, LOSS: 2.5535, AUC: 0.9084, AP: 0.9089\n",
      "Epoch: 189, LOSS: 2.5635, AUC: 0.9088, AP: 0.9093\n",
      "Epoch: 190, LOSS: 2.5310, AUC: 0.9091, AP: 0.9087\n",
      "Epoch: 191, LOSS: 2.4370, AUC: 0.9088, AP: 0.9078\n",
      "Epoch: 192, LOSS: 2.4922, AUC: 0.9094, AP: 0.9081\n",
      "Epoch: 193, LOSS: 2.5626, AUC: 0.9088, AP: 0.9077\n",
      "Epoch: 194, LOSS: 2.5185, AUC: 0.9078, AP: 0.9060\n",
      "Epoch: 195, LOSS: 2.4214, AUC: 0.9088, AP: 0.9067\n",
      "Epoch: 196, LOSS: 2.4840, AUC: 0.9084, AP: 0.9061\n",
      "Epoch: 197, LOSS: 2.6495, AUC: 0.9084, AP: 0.9064\n",
      "Epoch: 198, LOSS: 2.5121, AUC: 0.9084, AP: 0.9062\n",
      "Epoch: 199, LOSS: 2.4823, AUC: 0.9098, AP: 0.9076\n",
      "Epoch: 200, LOSS: 2.4056, AUC: 0.9104, AP: 0.9084\n",
      "Epoch: 201, LOSS: 2.5558, AUC: 0.9127, AP: 0.9108\n",
      "Epoch: 202, LOSS: 2.5451, AUC: 0.9121, AP: 0.9098\n",
      "Epoch: 203, LOSS: 2.5084, AUC: 0.9127, AP: 0.9107\n",
      "Epoch: 204, LOSS: 2.5166, AUC: 0.9124, AP: 0.9105\n",
      "Epoch: 205, LOSS: 2.4274, AUC: 0.9137, AP: 0.9119\n",
      "Epoch: 206, LOSS: 2.3198, AUC: 0.9150, AP: 0.9133\n",
      "Epoch: 207, LOSS: 2.4082, AUC: 0.9147, AP: 0.9130\n",
      "Epoch: 208, LOSS: 2.5125, AUC: 0.9154, AP: 0.9140\n",
      "Epoch: 209, LOSS: 2.4810, AUC: 0.9180, AP: 0.9160\n",
      "Epoch: 210, LOSS: 2.4013, AUC: 0.9183, AP: 0.9163\n",
      "Epoch: 211, LOSS: 2.4423, AUC: 0.9193, AP: 0.9176\n",
      "Epoch: 212, LOSS: 2.4211, AUC: 0.9187, AP: 0.9177\n",
      "Epoch: 213, LOSS: 2.3055, AUC: 0.9197, AP: 0.9190\n",
      "Epoch: 214, LOSS: 2.3135, AUC: 0.9200, AP: 0.9194\n",
      "Epoch: 215, LOSS: 2.2774, AUC: 0.9190, AP: 0.9182\n",
      "Epoch: 216, LOSS: 2.2405, AUC: 0.9193, AP: 0.9188\n",
      "Epoch: 217, LOSS: 2.4100, AUC: 0.9193, AP: 0.9188\n",
      "Epoch: 218, LOSS: 2.2856, AUC: 0.9197, AP: 0.9194\n",
      "Epoch: 219, LOSS: 2.2856, AUC: 0.9187, AP: 0.9184\n",
      "Epoch: 220, LOSS: 2.1814, AUC: 0.9193, AP: 0.9184\n",
      "Epoch: 221, LOSS: 2.3205, AUC: 0.9183, AP: 0.9175\n",
      "Epoch: 222, LOSS: 2.1787, AUC: 0.9180, AP: 0.9165\n",
      "Epoch: 223, LOSS: 2.2709, AUC: 0.9180, AP: 0.9162\n",
      "Epoch: 224, LOSS: 2.1676, AUC: 0.9160, AP: 0.9143\n",
      "Epoch: 225, LOSS: 2.1763, AUC: 0.9164, AP: 0.9141\n",
      "Epoch: 226, LOSS: 2.3537, AUC: 0.9164, AP: 0.9142\n",
      "Epoch: 227, LOSS: 2.1567, AUC: 0.9167, AP: 0.9143\n",
      "Epoch: 228, LOSS: 2.1730, AUC: 0.9177, AP: 0.9153\n",
      "Epoch: 229, LOSS: 2.2235, AUC: 0.9180, AP: 0.9155\n",
      "Epoch: 230, LOSS: 2.2023, AUC: 0.9187, AP: 0.9158\n",
      "Epoch: 231, LOSS: 2.2370, AUC: 0.9197, AP: 0.9166\n",
      "Epoch: 232, LOSS: 2.2144, AUC: 0.9217, AP: 0.9184\n",
      "Epoch: 233, LOSS: 2.1650, AUC: 0.9226, AP: 0.9190\n",
      "Epoch: 234, LOSS: 2.1403, AUC: 0.9230, AP: 0.9202\n",
      "Epoch: 235, LOSS: 2.0154, AUC: 0.9233, AP: 0.9206\n",
      "Epoch: 236, LOSS: 2.2447, AUC: 0.9236, AP: 0.9215\n",
      "Epoch: 237, LOSS: 2.0453, AUC: 0.9250, AP: 0.9226\n",
      "Epoch: 238, LOSS: 2.0908, AUC: 0.9246, AP: 0.9224\n",
      "Epoch: 239, LOSS: 2.1102, AUC: 0.9250, AP: 0.9229\n",
      "Epoch: 240, LOSS: 2.0790, AUC: 0.9233, AP: 0.9216\n",
      "Epoch: 241, LOSS: 2.1604, AUC: 0.9220, AP: 0.9205\n",
      "Epoch: 242, LOSS: 2.1624, AUC: 0.9220, AP: 0.9203\n",
      "Epoch: 243, LOSS: 2.1519, AUC: 0.9226, AP: 0.9202\n",
      "Epoch: 244, LOSS: 2.0695, AUC: 0.9220, AP: 0.9198\n",
      "Epoch: 245, LOSS: 2.1429, AUC: 0.9223, AP: 0.9201\n",
      "Epoch: 246, LOSS: 1.9940, AUC: 0.9220, AP: 0.9199\n",
      "Epoch: 247, LOSS: 2.0211, AUC: 0.9220, AP: 0.9197\n",
      "Epoch: 248, LOSS: 2.2543, AUC: 0.9217, AP: 0.9194\n",
      "Epoch: 249, LOSS: 2.0450, AUC: 0.9213, AP: 0.9191\n",
      "Epoch: 250, LOSS: 2.0057, AUC: 0.9217, AP: 0.9194\n",
      "Epoch: 251, LOSS: 1.9907, AUC: 0.9207, AP: 0.9186\n",
      "Epoch: 252, LOSS: 1.9850, AUC: 0.9210, AP: 0.9182\n",
      "Epoch: 253, LOSS: 2.0850, AUC: 0.9213, AP: 0.9186\n",
      "Epoch: 254, LOSS: 2.0962, AUC: 0.9210, AP: 0.9182\n",
      "Epoch: 255, LOSS: 2.0637, AUC: 0.9210, AP: 0.9182\n",
      "Epoch: 256, LOSS: 2.0808, AUC: 0.9217, AP: 0.9193\n",
      "Epoch: 257, LOSS: 1.9491, AUC: 0.9220, AP: 0.9195\n",
      "Epoch: 258, LOSS: 2.0152, AUC: 0.9220, AP: 0.9195\n",
      "Epoch: 259, LOSS: 2.0998, AUC: 0.9226, AP: 0.9201\n",
      "Epoch: 260, LOSS: 1.9434, AUC: 0.9226, AP: 0.9201\n",
      "Epoch: 261, LOSS: 2.0514, AUC: 0.9220, AP: 0.9194\n",
      "Epoch: 262, LOSS: 1.9707, AUC: 0.9226, AP: 0.9199\n",
      "Epoch: 263, LOSS: 2.0031, AUC: 0.9223, AP: 0.9194\n",
      "Epoch: 264, LOSS: 1.9665, AUC: 0.9236, AP: 0.9203\n",
      "Epoch: 265, LOSS: 1.9686, AUC: 0.9243, AP: 0.9210\n",
      "Epoch: 266, LOSS: 1.9635, AUC: 0.9250, AP: 0.9219\n",
      "Epoch: 267, LOSS: 1.9925, AUC: 0.9260, AP: 0.9226\n",
      "Epoch: 268, LOSS: 1.8988, AUC: 0.9266, AP: 0.9231\n",
      "Epoch: 269, LOSS: 1.9230, AUC: 0.9266, AP: 0.9231\n",
      "Epoch: 270, LOSS: 2.0345, AUC: 0.9263, AP: 0.9230\n",
      "Epoch: 271, LOSS: 1.9251, AUC: 0.9260, AP: 0.9227\n",
      "Epoch: 272, LOSS: 1.9197, AUC: 0.9256, AP: 0.9227\n",
      "Epoch: 273, LOSS: 1.9624, AUC: 0.9243, AP: 0.9219\n",
      "Epoch: 274, LOSS: 1.9586, AUC: 0.9240, AP: 0.9216\n",
      "Epoch: 275, LOSS: 1.8508, AUC: 0.9250, AP: 0.9223\n",
      "Epoch: 276, LOSS: 1.9626, AUC: 0.9260, AP: 0.9232\n",
      "Epoch: 277, LOSS: 1.9187, AUC: 0.9266, AP: 0.9236\n",
      "Epoch: 278, LOSS: 1.9204, AUC: 0.9263, AP: 0.9233\n",
      "Epoch: 279, LOSS: 1.9920, AUC: 0.9260, AP: 0.9232\n",
      "Epoch: 280, LOSS: 1.9877, AUC: 0.9260, AP: 0.9231\n",
      "Epoch: 281, LOSS: 1.8614, AUC: 0.9263, AP: 0.9233\n",
      "Epoch: 282, LOSS: 1.7522, AUC: 0.9266, AP: 0.9232\n",
      "Epoch: 283, LOSS: 1.9212, AUC: 0.9266, AP: 0.9232\n",
      "Epoch: 284, LOSS: 1.9862, AUC: 0.9269, AP: 0.9234\n",
      "Epoch: 285, LOSS: 1.9329, AUC: 0.9269, AP: 0.9234\n",
      "Epoch: 286, LOSS: 1.8683, AUC: 0.9266, AP: 0.9229\n",
      "Epoch: 287, LOSS: 1.8198, AUC: 0.9263, AP: 0.9227\n",
      "Epoch: 288, LOSS: 1.9508, AUC: 0.9263, AP: 0.9227\n",
      "Epoch: 289, LOSS: 1.9075, AUC: 0.9260, AP: 0.9228\n",
      "Epoch: 290, LOSS: 1.7413, AUC: 0.9256, AP: 0.9225\n",
      "Epoch: 291, LOSS: 1.8521, AUC: 0.9260, AP: 0.9227\n",
      "Epoch: 292, LOSS: 1.8806, AUC: 0.9260, AP: 0.9228\n",
      "Epoch: 293, LOSS: 1.7081, AUC: 0.9263, AP: 0.9230\n",
      "Epoch: 294, LOSS: 1.8337, AUC: 0.9263, AP: 0.9230\n",
      "Epoch: 295, LOSS: 1.7603, AUC: 0.9260, AP: 0.9228\n",
      "Epoch: 296, LOSS: 1.8803, AUC: 0.9279, AP: 0.9244\n",
      "Epoch: 297, LOSS: 1.6704, AUC: 0.9283, AP: 0.9246\n",
      "Epoch: 298, LOSS: 1.8500, AUC: 0.9286, AP: 0.9249\n",
      "Epoch: 299, LOSS: 1.8870, AUC: 0.9289, AP: 0.9250\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "for epoch in range(1,epochs):\n",
    "    loss = train()\n",
    "    loss = float(loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #valid_pos, valid_neg = data.val_pos_edge_index, data.val_neg_edge_index\n",
    "        auc, ap = test(data.val_pos_edge_index, data.val_neg_edge_index)\n",
    "        print('Epoch: {:03d}, LOSS: {:.4f}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, loss, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d3b38a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9289256198347108, 0.925048641648224)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(data.val_pos_edge_index, data.val_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0bf4563b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E370</td>\n",
       "      <td>0.402166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E667</td>\n",
       "      <td>0.942945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3190</td>\n",
       "      <td>0.906596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E848</td>\n",
       "      <td>0.865893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2161</td>\n",
       "      <td>0.787198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>E492</td>\n",
       "      <td>0.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>E3055</td>\n",
       "      <td>0.897925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>E1271</td>\n",
       "      <td>0.800694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>E2199</td>\n",
       "      <td>0.339961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>E2186</td>\n",
       "      <td>0.970777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      prob\n",
       "0     E370  0.402166\n",
       "1     E667  0.942945\n",
       "2    E3190  0.906596\n",
       "3     E848  0.865893\n",
       "4    E2161  0.787198\n",
       "..     ...       ...\n",
       "639   E492  0.302000\n",
       "640  E3055  0.897925\n",
       "641  E1271  0.800694\n",
       "642  E2199  0.339961\n",
       "643  E2186  0.970777\n",
       "\n",
       "[644 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode(x, data.train_pos_edge_index)\n",
    "Upload['prob'] = model.decoder(z,data.test,sigmoid = True).detach().cpu().numpy()\n",
    "Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9743dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upload.to_csv('output/VGNAE_change_test_encode_'+str(dss_num+1)+'.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
