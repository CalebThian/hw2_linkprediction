{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92548c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import pandas as pd\n",
    "import torch\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b619aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for i in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != len(self.convs) - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb619887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E370</td>\n",
       "      <td>26</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E667</td>\n",
       "      <td>196</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3190</td>\n",
       "      <td>739</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E848</td>\n",
       "      <td>576</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2161</td>\n",
       "      <td>466</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   to  from\n",
       "0   E370   26   317\n",
       "1   E667  196   323\n",
       "2  E3190  739   468\n",
       "3   E848  576   156\n",
       "4  E2161  466   199"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"hw2_data/\"\n",
    "dss = ['dataset1','dataset2','dataset3'] #datasets\n",
    "dataset = dict()\n",
    "for ds in dss:\n",
    "    dataset[ds] = dict()\n",
    "    dataset[ds]['content'] = pd.read_csv(path+ds+\"/content.csv\",delimiter = '\\t',header = None)\n",
    "    dataset[ds]['train'] = pd.read_csv(path+ds+\"/train.csv\",delimiter = ',')\n",
    "    dataset[ds]['test'] = pd.read_csv(path+ds+\"/test.csv\",delimiter = ',')\n",
    "    dataset[ds]['upload'] = pd.read_csv(path+ds+\"/upload.csv\",delimiter = ',')\n",
    "dataset[dss[2]]['test'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3ba2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7006578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccfc1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract node features and edges from the dataset\n",
    "x = dataset.data.x\n",
    "edge_index = dataset.data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a57fe937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6943, Train AUC: 0.4941\n",
      "Epoch: 002, Loss: 0.6929, Train AUC: 0.5171\n",
      "Epoch: 003, Loss: 0.6916, Train AUC: 0.5337\n",
      "Epoch: 004, Loss: 0.6907, Train AUC: 0.5404\n",
      "Epoch: 005, Loss: 0.6907, Train AUC: 0.5310\n",
      "Epoch: 006, Loss: 0.6891, Train AUC: 0.5473\n",
      "Epoch: 007, Loss: 0.6875, Train AUC: 0.5612\n",
      "Epoch: 008, Loss: 0.6865, Train AUC: 0.5492\n",
      "Epoch: 009, Loss: 0.6854, Train AUC: 0.5515\n",
      "Epoch: 010, Loss: 0.6845, Train AUC: 0.5512\n",
      "Epoch: 011, Loss: 0.6830, Train AUC: 0.5484\n",
      "Epoch: 012, Loss: 0.6818, Train AUC: 0.5505\n",
      "Epoch: 013, Loss: 0.6808, Train AUC: 0.5478\n",
      "Epoch: 014, Loss: 0.6790, Train AUC: 0.5586\n",
      "Epoch: 015, Loss: 0.6782, Train AUC: 0.5576\n",
      "Epoch: 016, Loss: 0.6768, Train AUC: 0.5444\n",
      "Epoch: 017, Loss: 0.6749, Train AUC: 0.5548\n",
      "Epoch: 018, Loss: 0.6740, Train AUC: 0.5651\n",
      "Epoch: 019, Loss: 0.6729, Train AUC: 0.5633\n",
      "Epoch: 020, Loss: 0.6721, Train AUC: 0.5577\n",
      "Epoch: 021, Loss: 0.6719, Train AUC: 0.5567\n",
      "Epoch: 022, Loss: 0.6691, Train AUC: 0.5741\n",
      "Epoch: 023, Loss: 0.6679, Train AUC: 0.5754\n",
      "Epoch: 024, Loss: 0.6666, Train AUC: 0.5727\n",
      "Epoch: 025, Loss: 0.6682, Train AUC: 0.5609\n",
      "Epoch: 026, Loss: 0.6666, Train AUC: 0.5669\n",
      "Epoch: 027, Loss: 0.6668, Train AUC: 0.5627\n",
      "Epoch: 028, Loss: 0.6647, Train AUC: 0.5701\n",
      "Epoch: 029, Loss: 0.6644, Train AUC: 0.5634\n",
      "Epoch: 030, Loss: 0.6647, Train AUC: 0.5642\n",
      "Epoch: 031, Loss: 0.6641, Train AUC: 0.5660\n",
      "Epoch: 032, Loss: 0.6622, Train AUC: 0.5741\n",
      "Epoch: 033, Loss: 0.6606, Train AUC: 0.5790\n",
      "Epoch: 034, Loss: 0.6619, Train AUC: 0.5758\n",
      "Epoch: 035, Loss: 0.6622, Train AUC: 0.5693\n",
      "Epoch: 036, Loss: 0.6599, Train AUC: 0.5836\n",
      "Epoch: 037, Loss: 0.6620, Train AUC: 0.5705\n",
      "Epoch: 038, Loss: 0.6599, Train AUC: 0.5786\n",
      "Epoch: 039, Loss: 0.6581, Train AUC: 0.5849\n",
      "Epoch: 040, Loss: 0.6580, Train AUC: 0.5908\n",
      "Epoch: 041, Loss: 0.6577, Train AUC: 0.5866\n",
      "Epoch: 042, Loss: 0.6593, Train AUC: 0.5754\n",
      "Epoch: 043, Loss: 0.6593, Train AUC: 0.5718\n",
      "Epoch: 044, Loss: 0.6564, Train AUC: 0.5912\n",
      "Epoch: 045, Loss: 0.6559, Train AUC: 0.5901\n",
      "Epoch: 046, Loss: 0.6571, Train AUC: 0.5842\n",
      "Epoch: 047, Loss: 0.6568, Train AUC: 0.5843\n",
      "Epoch: 048, Loss: 0.6564, Train AUC: 0.5812\n",
      "Epoch: 049, Loss: 0.6572, Train AUC: 0.5769\n",
      "Epoch: 050, Loss: 0.6569, Train AUC: 0.5782\n",
      "Epoch: 051, Loss: 0.6571, Train AUC: 0.5762\n",
      "Epoch: 052, Loss: 0.6557, Train AUC: 0.5847\n",
      "Epoch: 053, Loss: 0.6554, Train AUC: 0.5846\n",
      "Epoch: 054, Loss: 0.6553, Train AUC: 0.5827\n",
      "Epoch: 055, Loss: 0.6562, Train AUC: 0.5748\n",
      "Epoch: 056, Loss: 0.6543, Train AUC: 0.5888\n",
      "Epoch: 057, Loss: 0.6535, Train AUC: 0.5923\n",
      "Epoch: 058, Loss: 0.6540, Train AUC: 0.5870\n",
      "Epoch: 059, Loss: 0.6523, Train AUC: 0.5981\n",
      "Epoch: 060, Loss: 0.6529, Train AUC: 0.5865\n",
      "Epoch: 061, Loss: 0.6522, Train AUC: 0.5921\n",
      "Epoch: 062, Loss: 0.6525, Train AUC: 0.5841\n",
      "Epoch: 063, Loss: 0.6533, Train AUC: 0.5888\n",
      "Epoch: 064, Loss: 0.6525, Train AUC: 0.5842\n",
      "Epoch: 065, Loss: 0.6537, Train AUC: 0.5811\n",
      "Epoch: 066, Loss: 0.6518, Train AUC: 0.5926\n",
      "Epoch: 067, Loss: 0.6533, Train AUC: 0.5779\n",
      "Epoch: 068, Loss: 0.6516, Train AUC: 0.5913\n",
      "Epoch: 069, Loss: 0.6526, Train AUC: 0.5843\n",
      "Epoch: 070, Loss: 0.6537, Train AUC: 0.5792\n",
      "Epoch: 071, Loss: 0.6528, Train AUC: 0.5853\n",
      "Epoch: 072, Loss: 0.6515, Train AUC: 0.5906\n",
      "Epoch: 073, Loss: 0.6510, Train AUC: 0.5863\n",
      "Epoch: 074, Loss: 0.6524, Train AUC: 0.5762\n",
      "Epoch: 075, Loss: 0.6498, Train AUC: 0.5978\n",
      "Epoch: 076, Loss: 0.6512, Train AUC: 0.5877\n",
      "Epoch: 077, Loss: 0.6505, Train AUC: 0.5878\n",
      "Epoch: 078, Loss: 0.6505, Train AUC: 0.5848\n",
      "Epoch: 079, Loss: 0.6510, Train AUC: 0.5858\n",
      "Epoch: 080, Loss: 0.6506, Train AUC: 0.5853\n",
      "Epoch: 081, Loss: 0.6503, Train AUC: 0.5861\n",
      "Epoch: 082, Loss: 0.6516, Train AUC: 0.5748\n",
      "Epoch: 083, Loss: 0.6498, Train AUC: 0.5867\n",
      "Epoch: 084, Loss: 0.6502, Train AUC: 0.5863\n",
      "Epoch: 085, Loss: 0.6494, Train AUC: 0.5912\n",
      "Epoch: 086, Loss: 0.6478, Train AUC: 0.5940\n",
      "Epoch: 087, Loss: 0.6497, Train AUC: 0.5879\n",
      "Epoch: 088, Loss: 0.6479, Train AUC: 0.5947\n",
      "Epoch: 089, Loss: 0.6467, Train AUC: 0.6005\n",
      "Epoch: 090, Loss: 0.6489, Train AUC: 0.5863\n",
      "Epoch: 091, Loss: 0.6474, Train AUC: 0.5966\n",
      "Epoch: 092, Loss: 0.6473, Train AUC: 0.5895\n",
      "Epoch: 093, Loss: 0.6457, Train AUC: 0.6001\n",
      "Epoch: 094, Loss: 0.6486, Train AUC: 0.5880\n",
      "Epoch: 095, Loss: 0.6471, Train AUC: 0.5918\n",
      "Epoch: 096, Loss: 0.6471, Train AUC: 0.5930\n",
      "Epoch: 097, Loss: 0.6469, Train AUC: 0.5961\n",
      "Epoch: 098, Loss: 0.6472, Train AUC: 0.5908\n",
      "Epoch: 099, Loss: 0.6465, Train AUC: 0.5970\n",
      "Epoch: 100, Loss: 0.6480, Train AUC: 0.5826\n",
      "Epoch: 101, Loss: 0.6470, Train AUC: 0.5898\n",
      "Epoch: 102, Loss: 0.6471, Train AUC: 0.5847\n",
      "Epoch: 103, Loss: 0.6466, Train AUC: 0.5937\n",
      "Epoch: 104, Loss: 0.6452, Train AUC: 0.5976\n",
      "Epoch: 105, Loss: 0.6459, Train AUC: 0.5928\n",
      "Epoch: 106, Loss: 0.6458, Train AUC: 0.5940\n",
      "Epoch: 107, Loss: 0.6469, Train AUC: 0.5828\n",
      "Epoch: 108, Loss: 0.6478, Train AUC: 0.5842\n",
      "Epoch: 109, Loss: 0.6453, Train AUC: 0.5906\n",
      "Epoch: 110, Loss: 0.6443, Train AUC: 0.5988\n",
      "Epoch: 111, Loss: 0.6439, Train AUC: 0.5931\n",
      "Epoch: 112, Loss: 0.6457, Train AUC: 0.5900\n",
      "Epoch: 113, Loss: 0.6449, Train AUC: 0.5887\n",
      "Epoch: 114, Loss: 0.6448, Train AUC: 0.5938\n",
      "Epoch: 115, Loss: 0.6455, Train AUC: 0.5843\n",
      "Epoch: 116, Loss: 0.6452, Train AUC: 0.5864\n",
      "Epoch: 117, Loss: 0.6439, Train AUC: 0.5913\n",
      "Epoch: 118, Loss: 0.6448, Train AUC: 0.5830\n",
      "Epoch: 119, Loss: 0.6440, Train AUC: 0.5896\n",
      "Epoch: 120, Loss: 0.6426, Train AUC: 0.6015\n",
      "Epoch: 121, Loss: 0.6441, Train AUC: 0.5866\n",
      "Epoch: 122, Loss: 0.6441, Train AUC: 0.5877\n",
      "Epoch: 123, Loss: 0.6448, Train AUC: 0.5867\n",
      "Epoch: 124, Loss: 0.6431, Train AUC: 0.6024\n",
      "Epoch: 125, Loss: 0.6433, Train AUC: 0.5879\n",
      "Epoch: 126, Loss: 0.6422, Train AUC: 0.5928\n",
      "Epoch: 127, Loss: 0.6430, Train AUC: 0.5916\n",
      "Epoch: 128, Loss: 0.6429, Train AUC: 0.5883\n",
      "Epoch: 129, Loss: 0.6440, Train AUC: 0.5790\n",
      "Epoch: 130, Loss: 0.6424, Train AUC: 0.5895\n",
      "Epoch: 131, Loss: 0.6416, Train AUC: 0.6010\n",
      "Epoch: 132, Loss: 0.6423, Train AUC: 0.5926\n",
      "Epoch: 133, Loss: 0.6416, Train AUC: 0.5913\n",
      "Epoch: 134, Loss: 0.6416, Train AUC: 0.6009\n",
      "Epoch: 135, Loss: 0.6421, Train AUC: 0.5904\n",
      "Epoch: 136, Loss: 0.6415, Train AUC: 0.5859\n",
      "Epoch: 137, Loss: 0.6407, Train AUC: 0.5923\n",
      "Epoch: 138, Loss: 0.6421, Train AUC: 0.5883\n",
      "Epoch: 139, Loss: 0.6409, Train AUC: 0.5972\n",
      "Epoch: 140, Loss: 0.6401, Train AUC: 0.5956\n",
      "Epoch: 141, Loss: 0.6435, Train AUC: 0.5856\n",
      "Epoch: 142, Loss: 0.6408, Train AUC: 0.5886\n",
      "Epoch: 143, Loss: 0.6419, Train AUC: 0.5880\n",
      "Epoch: 144, Loss: 0.6412, Train AUC: 0.5881\n",
      "Epoch: 145, Loss: 0.6405, Train AUC: 0.5886\n",
      "Epoch: 146, Loss: 0.6404, Train AUC: 0.5867\n",
      "Epoch: 147, Loss: 0.6410, Train AUC: 0.5897\n",
      "Epoch: 148, Loss: 0.6405, Train AUC: 0.5896\n",
      "Epoch: 149, Loss: 0.6414, Train AUC: 0.5882\n",
      "Epoch: 150, Loss: 0.6406, Train AUC: 0.5936\n",
      "Epoch: 151, Loss: 0.6410, Train AUC: 0.5897\n",
      "Epoch: 152, Loss: 0.6407, Train AUC: 0.5989\n",
      "Epoch: 153, Loss: 0.6403, Train AUC: 0.5980\n",
      "Epoch: 154, Loss: 0.6399, Train AUC: 0.5923\n",
      "Epoch: 155, Loss: 0.6409, Train AUC: 0.5856\n",
      "Epoch: 156, Loss: 0.6401, Train AUC: 0.5902\n",
      "Epoch: 157, Loss: 0.6390, Train AUC: 0.5915\n",
      "Epoch: 158, Loss: 0.6388, Train AUC: 0.6004\n",
      "Epoch: 159, Loss: 0.6403, Train AUC: 0.5925\n",
      "Epoch: 160, Loss: 0.6392, Train AUC: 0.5924\n",
      "Epoch: 161, Loss: 0.6402, Train AUC: 0.5869\n",
      "Epoch: 162, Loss: 0.6387, Train AUC: 0.5921\n",
      "Epoch: 163, Loss: 0.6417, Train AUC: 0.5796\n",
      "Epoch: 164, Loss: 0.6411, Train AUC: 0.5784\n",
      "Epoch: 165, Loss: 0.6383, Train AUC: 0.5950\n",
      "Epoch: 166, Loss: 0.6407, Train AUC: 0.5819\n",
      "Epoch: 167, Loss: 0.6403, Train AUC: 0.5871\n",
      "Epoch: 168, Loss: 0.6389, Train AUC: 0.5954\n",
      "Epoch: 169, Loss: 0.6391, Train AUC: 0.5886\n",
      "Epoch: 170, Loss: 0.6394, Train AUC: 0.5901\n",
      "Epoch: 171, Loss: 0.6403, Train AUC: 0.5862\n",
      "Epoch: 172, Loss: 0.6397, Train AUC: 0.5889\n",
      "Epoch: 173, Loss: 0.6400, Train AUC: 0.5837\n",
      "Epoch: 174, Loss: 0.6385, Train AUC: 0.5892\n",
      "Epoch: 175, Loss: 0.6384, Train AUC: 0.5893\n",
      "Epoch: 176, Loss: 0.6368, Train AUC: 0.5957\n",
      "Epoch: 177, Loss: 0.6393, Train AUC: 0.5862\n",
      "Epoch: 178, Loss: 0.6381, Train AUC: 0.5904\n",
      "Epoch: 179, Loss: 0.6397, Train AUC: 0.5871\n",
      "Epoch: 180, Loss: 0.6381, Train AUC: 0.5892\n",
      "Epoch: 181, Loss: 0.6382, Train AUC: 0.5933\n",
      "Epoch: 182, Loss: 0.6383, Train AUC: 0.5796\n",
      "Epoch: 183, Loss: 0.6381, Train AUC: 0.5826\n",
      "Epoch: 184, Loss: 0.6389, Train AUC: 0.5826\n",
      "Epoch: 185, Loss: 0.6374, Train AUC: 0.5946\n",
      "Epoch: 186, Loss: 0.6369, Train AUC: 0.5926\n",
      "Epoch: 187, Loss: 0.6384, Train AUC: 0.5881\n",
      "Epoch: 188, Loss: 0.6368, Train AUC: 0.5917\n",
      "Epoch: 189, Loss: 0.6372, Train AUC: 0.5873\n",
      "Epoch: 190, Loss: 0.6362, Train AUC: 0.5960\n",
      "Epoch: 191, Loss: 0.6375, Train AUC: 0.5855\n",
      "Epoch: 192, Loss: 0.6382, Train AUC: 0.5825\n",
      "Epoch: 193, Loss: 0.6374, Train AUC: 0.5903\n",
      "Epoch: 194, Loss: 0.6356, Train AUC: 0.5942\n",
      "Epoch: 195, Loss: 0.6356, Train AUC: 0.5884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 196, Loss: 0.6356, Train AUC: 0.5913\n",
      "Epoch: 197, Loss: 0.6360, Train AUC: 0.5921\n",
      "Epoch: 198, Loss: 0.6362, Train AUC: 0.5844\n",
      "Epoch: 199, Loss: 0.6363, Train AUC: 0.5894\n",
      "Epoch: 200, Loss: 0.6372, Train AUC: 0.5869\n"
     ]
    }
   ],
   "source": [
    "# Define a binary classification task for link prediction\n",
    "train_mask = dataset.data.train_mask\n",
    "pos_edge_index = edge_index[:, torch.where(train_mask)[0]]\n",
    "neg_edge_index = negative_sampling(\n",
    "    edge_index=edge_index, num_nodes=dataset.data.num_nodes,\n",
    "    num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "x = nn.functional.normalize(x, p=2, dim=-1)\n",
    "\n",
    "# Train the model on the positive and negative edges\n",
    "model = GraphSAGE(in_channels=dataset.num_features, hidden_channels=16,\n",
    "                  out_channels=1, num_layers=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    pos_pred = model(x, pos_edge_index).flatten()\n",
    "    neg_pred = model(x, neg_edge_index).flatten()\n",
    "    pred = torch.cat([pos_pred, neg_pred])\n",
    "    pos_labels = torch.ones(pos_pred.size(0), dtype=torch.float)\n",
    "    neg_labels = torch.zeros(neg_pred.size(0), dtype=torch.float)\n",
    "    labels = torch.cat([pos_labels, neg_labels])\n",
    "    loss = criterion(pred, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_auc = roc_auc_score(labels.cpu().detach().numpy(), \n",
    "                              pred.cpu().detach().numpy())\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:03d}, Loss: {loss:.4f}, Train AUC: {train_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c321b5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.5211\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on a test set of positive and negative edges\n",
    "test_mask = dataset.data.test_mask\n",
    "pos_edge_index = edge_index[:, torch.where(test_mask)[0]]\n",
    "neg_edge_index = negative_sampling(\n",
    "    edge_index=edge_index, num_nodes=dataset.data.num_nodes,\n",
    "    num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pos_pred = model(x, pos_edge_index).flatten()\n",
    "    neg_pred = model(x, neg_edge_index).flatten()\n",
    "    pred = torch.cat([pos_pred, neg_pred])\n",
    "    pos_labels = torch.ones(pos_pred.size(0), dtype=torch.float)\n",
    "    neg_labels = torch.zeros(neg_pred.size(0), dtype=torch.float)\n",
    "    labels = torch.cat([pos_labels, neg_labels])\n",
    "    test_auc = roc_auc_score(labels.cpu().detach().numpy(), \n",
    "                             pred.cpu().detach().numpy())\n",
    "    print(f'Test AUC: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5729c0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2ba1a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset.data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d49aedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8124"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2708*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9599b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
