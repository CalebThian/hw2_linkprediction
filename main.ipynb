{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2df931a",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bdc5e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_undirected, from_scipy_sparse_matrix,dense_to_sparse,is_undirected\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import softmax\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Parameter,Embedding\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_mean, scatter, scatter_add, scatter_max\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27941b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E370</td>\n",
       "      <td>26</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E667</td>\n",
       "      <td>196</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3190</td>\n",
       "      <td>739</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E848</td>\n",
       "      <td>576</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2161</td>\n",
       "      <td>466</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   to  from\n",
       "0   E370   26   317\n",
       "1   E667  196   323\n",
       "2  E3190  739   468\n",
       "3   E848  576   156\n",
       "4  E2161  466   199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"hw2_data/\"\n",
    "dss = ['dataset1','dataset2','dataset3'] #datasets\n",
    "dataset = dict()\n",
    "for ds in dss:\n",
    "    dataset[ds] = dict()\n",
    "    dataset[ds]['content'] = pd.read_csv(path+ds+\"/content.csv\",delimiter = '\\t',header = None)\n",
    "    dataset[ds]['train'] = pd.read_csv(path+ds+\"/train.csv\",delimiter = ',')\n",
    "    dataset[ds]['test'] = pd.read_csv(path+ds+\"/test.csv\",delimiter = ',')\n",
    "    dataset[ds]['upload'] = pd.read_csv(path+ds+\"/upload.csv\",delimiter = ',')\n",
    "dataset[dss[2]]['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0da49",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222d51e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 1434)\n",
      "2708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1433,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[dss[0]]['content'].shape)\n",
    "print(len(dataset[dss[0]]['content']))\n",
    "np.array(dataset[dss[0]]['content'].iloc[0,1:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2563c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8686, 4)\n",
      "8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2397"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[dss[0]]['train'].shape)\n",
    "print(len(dataset[dss[0]]['train']))\n",
    "dataset[dss[0]]['train'].loc[1,'to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c400784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edge(0,1,label=0)\n",
    "G.add_edge(0,2,label=1)\n",
    "G.add_edge(1,2,label=1)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b7b149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2, 1), (1, 2, 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in list(G.edges.data('label')) if e[2]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6401abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example:\n",
    "Content = dataset[dss[0]]['content']\n",
    "Train = dataset[dss[0]]['train']\n",
    "Test = dataset[dss[0]]['test']\n",
    "Upload = dataset[dss[0]]['upload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb0319c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1434)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af37fe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E10311</td>\n",
       "      <td>2399</td>\n",
       "      <td>2339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E10667</td>\n",
       "      <td>854</td>\n",
       "      <td>1726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E9395</td>\n",
       "      <td>872</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E485</td>\n",
       "      <td>384</td>\n",
       "      <td>1277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E2160</td>\n",
       "      <td>97</td>\n",
       "      <td>1861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>E2236</td>\n",
       "      <td>1717</td>\n",
       "      <td>1875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>E9767</td>\n",
       "      <td>1458</td>\n",
       "      <td>1503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>E7438</td>\n",
       "      <td>2682</td>\n",
       "      <td>1893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>E1729</td>\n",
       "      <td>862</td>\n",
       "      <td>1761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681</th>\n",
       "      <td>E1171</td>\n",
       "      <td>1643</td>\n",
       "      <td>1383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    to  from  label\n",
       "0     E10311  2399  2339      0\n",
       "2     E10667   854  1726      0\n",
       "3      E9395   872   702      0\n",
       "5       E485   384  1277      0\n",
       "7      E2160    97  1861      0\n",
       "...      ...   ...   ...    ...\n",
       "8668   E2236  1717  1875      0\n",
       "8670   E9767  1458  1503      0\n",
       "8671   E7438  2682  1893      0\n",
       "8678   E1729   862  1761      0\n",
       "8681   E1171  1643  1383      0\n",
       "\n",
       "[4362 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[Train['label']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b5e9f",
   "metadata": {},
   "source": [
    "---\n",
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3980e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da085f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd7d9e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9327be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor(x):\n",
    "    return torch.div(x, 1, rounding_mode='trunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44349bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    # Row-normalize feature matrix and convert to tuple representation\n",
    "    # Because the datasets only have binary features, row-normalize is unnecessary\n",
    "    rowsum = np.array(features.sum(1),dtype = np.float32)\n",
    "    rowsum = (rowsum==0)*1+rowsum\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d2e8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(content,train, test):\n",
    "    G = nx.DiGraph()\n",
    "    G_test = nx.DiGraph()\n",
    "    # for easier split the edges, create 2 graph, 1 with positive edge, the other with given negative edges\n",
    "    G_pos = nx.DiGraph()\n",
    "    G_neg = nx.DiGraph()\n",
    "    graph_node_features_dict = dict()\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        #graph_node_features_dict[content.iloc[i,0]] = np.array(content.iloc[i,1:])\n",
    "        G.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        G_test.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        # pos and neg\n",
    "        G_pos.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        G_neg.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        \n",
    "    for i in range(len(train)):\n",
    "        # Adding nodes into G\n",
    "        '''\n",
    "        if train.loc[i,'from'] not in G:\n",
    "            G.add_node(train.loc[i,'from'],features = graph_node_features_dict[train.loc[i,'from']])\n",
    "        if train.loc[i,'to'] not in G:\n",
    "            G.add_node(train.loc[i,'to'],features = graph_node_features_dict[train.loc[i,'to']])\n",
    "        ''' \n",
    "        # Adding edges\n",
    "        G.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "        \n",
    "        # pos and neg\n",
    "        if train.loc[i,'label'] == 0: \n",
    "            G_neg.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "        else:\n",
    "            G_pos.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        # Adding edges\n",
    "        G_test.add_edge(test.loc[i,'from'],test.loc[i,'to'])\n",
    "    \n",
    "    adj = nx.adjacency_matrix(G,sorted(G.nodes()))\n",
    "    adj_test = nx.adjacency_matrix(G_test,sorted(G_test.nodes()))\n",
    "    adj_pos = nx.adjacency_matrix(G_pos,sorted(G_pos.nodes()))\n",
    "    adj_neg = nx.adjacency_matrix(G_neg,sorted(G_neg.nodes()))\n",
    "    features = np.array(\n",
    "        [features for _, features in sorted(G.nodes(data='features'), key=lambda x: x[0])])\n",
    "    features = preprocess_features(features)\n",
    "    \n",
    "    # Skip train,valid,and test mask\n",
    "    \n",
    "    num_features = features.shape[1]\n",
    "    features = torch.FloatTensor(features)\n",
    "    return adj, adj_test, adj_pos, adj_neg, features, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e6b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, gtest, pos, neg, features, num_features = load_data(Content,Train,Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a433235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edges(data):\n",
    "    set_random_seed(10) #Seed is randomly set\n",
    "    \n",
    "    # ? This select the edges that from<to, but why? Don't understand, not using this\n",
    "    row, col = data.edge_index\n",
    "    mask = row < col\n",
    "    row, col = row[mask], col[mask]\n",
    "    \n",
    "    val_ratio = 0.1\n",
    "    #test_ratio = 0.1\n",
    "    \n",
    "    #split positive edges\n",
    "    row_pos, col_pos = data.pos\n",
    "    #mask_pos = row_pos < col_pos\n",
    "    #row_pos, col_pos = row_pos[mask_pos], col_pos[mask_pos]\n",
    "    \n",
    "    \n",
    "    n_v = floor(val_ratio * row_pos.size(0)).int() #number of validation positive edges\n",
    "    #n_t = floor(test_ratio * row_pos.size(0)).int() #number of test positive edges\n",
    "    \n",
    "    perm = torch.randperm(row_pos.size(0))\n",
    "    row_pos, col_pos = row_pos[perm], col_pos[perm]\n",
    "    r, c = row_pos[:n_v], col_pos[:n_v]\n",
    "    data.val_pos = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_pos[n_v:n_v+n_t], col_pos[n_v:n_v+n_t]\n",
    "    #data.test_pos = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_pos[n_v+n_t:], col_pos[n_v+n_t:]\n",
    "    r, c = row_pos[n_v:], col_pos[n_v:]\n",
    "    data.train_pos = torch.stack([r, c], dim=0)\n",
    "    print(\"Positive edges shape(train,val):\",end=\"\")\n",
    "    #print(data.train_pos.shape,data.test_pos.shape,data.val_pos.shape)\n",
    "    print(data.train_pos.shapee,data.val_pos.shape)\n",
    "    \n",
    "    #split neg edges\n",
    "    row_neg, col_neg = data.neg\n",
    "    #mask_neg = row_neg < col_neg\n",
    "    #row_neg, col_neg = row_neg[mask_neg], col_neg[mask_neg]\n",
    "    \n",
    "    \n",
    "    n_v = floor(val_ratio * row_neg.size(0)).int() #number of validation positive edges\n",
    "    #n_t = floor(test_ratio * row_neg.size(0)).int() #number of test positive edges\n",
    "    \n",
    "    perm = torch.randperm(row_neg.size(0))\n",
    "    row_neg, col_neg = row_neg[perm], col_neg[perm]\n",
    "    r, c = row_neg[:n_v], col_neg[:n_v]\n",
    "    data.val_neg = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_neg[n_v:n_v+n_t], col_neg[n_v:n_v+n_t]\n",
    "    #data.test_neg = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_neg[n_v+n_t:], col_neg[n_v+n_t:]\n",
    "    r, c = row_neg[n_v:], col_neg[n_v:]\n",
    "    data.train_neg = torch.stack([r, c], dim=0)\n",
    "    print(\"Negative edges shape(train,val):\",end=\"\")\n",
    "    #print(data.train_neg.shape,data.test_neg.shape,data.val_neg.shape)\n",
    "    print(data.train_neg.shape,data.val_neg.shape)\n",
    "\n",
    "    #costruct real test edges\n",
    "    row_test,col_test = data.test\n",
    "    data.test = torch.stack([row_test,col_test],dim = 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bebf0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_init_attribute_representation(data):\n",
    "    # Construct data_observed and compute its node attributes & representation\n",
    "    # Why create undirected edge? Don't use this\n",
    "    # Now pretend args.observe_val_and_injection = False\n",
    "    #print('Here')\n",
    "    #print(data.train_pos.shape,data.train_pos[[1,0],:].shape)\n",
    "    #print(data.train_pos,data.train_pos[[1,0],:])\n",
    "    #print(data.train_pos[:,:],,data.train_pos[[1,0],:])\n",
    "    #edge_index = torch.cat((data.train_pos,data.train_pos[[1,0],:]),dim=1)\n",
    "    #print(edge_index)\n",
    "    edge_index = data.train_pos\n",
    "    #edge_index=torch.cat((edge_index,data.val_pos,data.val_pos[[1,0],:]),dim=1)\n",
    "    data_observed = Data(edge_index=edge_index)\n",
    "    data_observed.num_nodes = data.num_nodes\n",
    "    #use the injection trick and add val data in observed graph \n",
    "    #edge_index_observed = torch.cat((data_observed.edge_index,\\\n",
    "    #    data.train_neg,data.train_neg[[1,0],:],data.val_neg,data.val_neg[[1,0],:]),dim=1)\n",
    "    edge_index_observed = data_observed.edge_index\n",
    "  \n",
    "    #generate the initial node attribute if there isn't any\n",
    "    init_attribute = 'n2v' # Can choose between 'n2v','one_hot','spc','ones','zeros',\n",
    "    # But we already prepare features so it doesn't matter\n",
    "    if data.x == None:\n",
    "        if init_attribute =='n2v':\n",
    "            from node2vec import CalN2V\n",
    "            x = CalN2V(edge_index_observed)#,args)\n",
    "        if init_attribute =='one_hot':\n",
    "            x = F.one_hot(torch.arange(data.num_nodes), num_classes=data.num_nodes)\n",
    "            x = x.float()\n",
    "        if init_attribute =='spc':\n",
    "            from SPC import spc\n",
    "            x = spc(edge_index_observed)#,args)\n",
    "            x = x.float()\n",
    "        if init_attribute =='ones':\n",
    "            embedding_dim = 32\n",
    "            x = torch.ones(data.num_nodes,args.embedding_dim)\n",
    "            x = x.float()\n",
    "        if init_attribute =='zeros':\n",
    "            embedding_dim = 32\n",
    "            x = torch.zeros(data.num_nodes,args.embedding_dim)\n",
    "            x = x.float()\n",
    "    else:\n",
    "        x = data.x\n",
    "    #generate the initial node representation using unsupervised models\n",
    "    \n",
    "    init_representation = None # Don't understand what this part doing\n",
    "    if init_representation != None:\n",
    "        val_and_test=[data.test_pos,data.test_neg,data.val_pos,data.val_neg]\n",
    "        num_nodes,_=x.shape\n",
    "        #add self-loop for the last node to aviod losing node if the last node dosen't have a link.\n",
    "        if (num_nodes-1) in edge_index_observed:\n",
    "            edge_index_observed=edge_index_observed.clone().detach()\n",
    "        else:\n",
    "            edge_index_observed=torch.cat((edge_index_observed.clone().detach(),torch.tensor([[num_nodes-1],[num_nodes-1]])),dim=1)\n",
    "        if init_representation == 'gic':\n",
    "            par_dir = os.path.abspath(os.path.join(os.path.dirname(__file__),\"..\"))\n",
    "            sys.path.append('%s/software/GIC/' % args.par_dir)\n",
    "            from GICEmbs import CalGIC\n",
    "            data_observed.x, auc, ap = CalGIC(edge_index_observed, x, args.data_name, val_and_test,args)\n",
    "\n",
    "        if init_representation == 'vgae':\n",
    "            from vgae import CalVGAE\n",
    "            data_observed.x, auc, ap = CalVGAE(edge_index_observed, x, val_and_test, args)\n",
    "        if init_representation == 'svgae':\n",
    "            from svgae import CalSVGAE\n",
    "            data_observed.x, auc, ap = CalSVGAE(edge_index_observed, x, val_and_test, args)\n",
    "        if init_representation == 'argva':\n",
    "            from argva import CalARGVA\n",
    "            data_observed.x, auc, ap = CalARGVA(edge_index_observed, x, val_and_test, args)\n",
    "        feature_results=[auc,ap]\n",
    "    else:\n",
    "        data_observed.x = x\n",
    "        feature_results=None\n",
    "\n",
    "    return data_observed,feature_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce585441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_hop_subgraph(node_idx, num_hops, edge_index, max_nodes_per_hop = None,num_nodes = None):\n",
    "  \n",
    "    if num_nodes == None:\n",
    "        num_nodes = torch.max(edge_index)+1\n",
    "    row, col = edge_index\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    node_idx = node_idx.to(row.device)\n",
    "\n",
    "    subsets = [node_idx]\n",
    "\n",
    "    if max_nodes_per_hop == None:\n",
    "        for _ in range(num_hops):\n",
    "            node_mask.fill_(False)\n",
    "            node_mask[subsets[-1]] = True\n",
    "            torch.index_select(node_mask, 0, row, out = edge_mask)\n",
    "            subsets.append(col[edge_mask])\n",
    "    else:\n",
    "        not_visited = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "        not_visited.fill_(True)\n",
    "        for _ in range(num_hops):\n",
    "            node_mask.fill_(False)# the source node mask in this hop\n",
    "            node_mask[subsets[-1]] = True #mark the sources\n",
    "            not_visited[subsets[-1]] = False # mark visited nodes\n",
    "            torch.index_select(node_mask, 0, row, out = edge_mask) # indices of all neighbors\n",
    "            neighbors = col[edge_mask].unique() #remove repeats\n",
    "            neighbor_mask = row.new_empty(num_nodes, dtype=torch.bool) # mask of all neighbor nodes\n",
    "            edge_mask_hop = row.new_empty(row.size(0), dtype=torch.bool) # selected neighbor mask in this hop\n",
    "            neighbor_mask.fill_(False)\n",
    "            neighbor_mask[neighbors] = True\n",
    "            neighbor_mask = torch.logical_and(neighbor_mask, not_visited) # all neighbors that are not visited\n",
    "            ind = torch.where(neighbor_mask==True) #indicies of all the unvisited neighbors\n",
    "            if ind[0].size(0) > max_nodes_per_hop:\n",
    "                perm = torch.randperm(ind[0].size(0))\n",
    "                ind = ind[0][perm]\n",
    "                neighbor_mask[ind[max_nodes_per_hop:]] = False # randomly select max_nodes_per_hop nodes\n",
    "                torch.index_select(neighbor_mask, 0, col, out = edge_mask_hop)# find the indicies of selected nodes\n",
    "                edge_mask = torch.logical_and(edge_mask,edge_mask_hop) # change edge_mask\n",
    "            subsets.append(col[edge_mask])\n",
    "\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "    inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    node_idx = row.new_full((num_nodes, ), -1)\n",
    "    node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "    edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, inv, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac382c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus_edge(data_observed, label, p_edge):\n",
    "    num_hops = 2 # number of hops in sampling subgraph, set 2 which same as default\n",
    "    max_nodes_per_hop =  None #when the graph is too large or too dense, \n",
    "    #we need max node per hop threshold to avoid OOM. Default is None\n",
    "    nodes, edge_index_m, mapping, _ = k_hop_subgraph(node_idx= p_edge, num_hops= num_hops,\\\n",
    " edge_index = data_observed.edge_index, max_nodes_per_hop= max_nodes_per_hop ,num_nodes=data_observed.num_nodes)\n",
    "    x_sub = data_observed.x[nodes,:]\n",
    "    edge_index_p = edge_index_m\n",
    "    edge_index_p = torch.cat((edge_index_p, mapping.view(-1,1)),dim=1)\n",
    "    edge_index_p = torch.cat((edge_index_p, mapping[[1,0]].view(-1,1)),dim=1)\n",
    "\n",
    "    #edge_mask marks the edge under perturbation, i.e., the candidate edge for LP\n",
    "    edge_mask = torch.ones(edge_index_p.size(1),dtype=torch.bool)\n",
    "    edge_mask[-1] = False\n",
    "    edge_mask[-2] = False\n",
    "    \n",
    "    '''\n",
    "    # Run here for drnl labeling\n",
    "    if drnl == True:\n",
    "        num_nodes = torch.max(edge_index_p)+1\n",
    "        z = drnl_node_labeling(edge_index_m, mapping[0],mapping[1],num_nodes)\n",
    "        data = Data(edge_index = edge_index_p, x = x_sub, z = z)\n",
    "    '''\n",
    "    data = Data(edge_index = edge_index_p, x = x_sub, z = 0)\n",
    "    data.edge_mask = edge_mask\n",
    "\n",
    "    #label = 1 if the candidate link (p_edge) is positive and label=0 otherwise\n",
    "    data.label = float(label)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59e2764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_edge(data_observed, label, p_edge):\n",
    "    num_hops = 2 # number of hops in sampling subgraph, set 2 which same as default\n",
    "    max_nodes_per_hop =  None #when the graph is too large or too dense, \n",
    "    #we need max node per hop threshold to avoid OOM. Default is None\n",
    "    \n",
    "    nodes, edge_index_p, mapping,_ = k_hop_subgraph(node_idx= p_edge, num_hops=num_hops,\\\n",
    " edge_index = data_observed.edge_index,max_nodes_per_hop=max_nodes_per_hop, num_nodes = data_observed.num_nodes)\n",
    "    x_sub = data_observed.x[nodes,:]\n",
    "\n",
    "    #edge_mask marks the edge under perturbation, i.e., the candidate edge for LP\n",
    "    edge_mask = torch.ones(edge_index_p.size(1), dtype = torch.bool)\n",
    "    ind = torch.where((edge_index_p == mapping.view(-1,1)).all(dim=0))\n",
    "    edge_mask[ind[0]] = False\n",
    "    ind = torch.where((edge_index_p == mapping[[1,0]].view(-1,1)).all(dim=0))\n",
    "    edge_mask[ind[0]] = False\n",
    "    '''\n",
    "    if args.drnl == True:\n",
    "        num_nodes = torch.max(edge_index_p)+1\n",
    "        z = drnl_node_labeling(edge_index_p[:,edge_mask], mapping[0],mapping[1],num_nodes)\n",
    "        data = Data(edge_index = edge_index_p, x= x_sub,z = z)\n",
    "    else:\n",
    "    '''\n",
    "    data = Data(edge_index = edge_index_p, x= x_sub,z = 0)\n",
    "    data.edge_mask = edge_mask\n",
    "\n",
    "    #label = 1 if the candidate link (p_edge) is positive and label=0 otherwise\n",
    "    data.label = float(label)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbe9c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "def prepare_data(content,train,test):\n",
    "    g, gtest, pos, neg, features, num_features = load_data(content,train,test)\n",
    "    A = g.toarray()\n",
    "    edge_index,_ = dense_to_sparse(torch.tensor(A))\n",
    "    Atest = gtest.toarray()\n",
    "    edge_index_test,_ = dense_to_sparse(torch.tensor(Atest))\n",
    "    Apos = pos.toarray()\n",
    "    edge_index_pos,_ = dense_to_sparse(torch.tensor(Apos))\n",
    "    Aneg = neg.toarray()\n",
    "    edge_index_neg,_ = dense_to_sparse(torch.tensor(Aneg))\n",
    "    data = Data(edge_index=edge_index,x=features.to(torch.float),\n",
    "                pos = edge_index_pos,neg = edge_index_neg,test = edge_index_test)\n",
    "    data = split_edges(data)\n",
    "    \n",
    "\n",
    "    set_random_seed(42) # Random set the seed\n",
    "    data_observed,feature_results= set_init_attribute_representation(data)\n",
    "    # Construct train, val and test data loader\n",
    "    set_random_seed(42)\n",
    "    train_graphs = []\n",
    "    val_graphs = []\n",
    "    test_graphs = []\n",
    "    for i in range(data.train_pos.size(1)):\n",
    "        train_graphs.append(minus_edge(data_observed,1,data.train_pos[:,i]))\n",
    "\n",
    "    for i in range(data.train_neg.size(1)):\n",
    "        train_graphs.append(plus_edge(data_observed,0,data.train_neg[:,i]))\n",
    "    '''\n",
    "    for i in range(data.test_pos.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,1,data.test_pos[:,i]))\n",
    "\n",
    "    for i in range(data.test_neg.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,0,data.test_neg[:,i]))   \n",
    "    '''\n",
    "    for i in range(data.test.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,1,data.test[:,i]))\n",
    "    \n",
    "    #if args.observe_val_and_injection == False:\n",
    "    # pretend args.observe_val_and_injection == False\n",
    "    for i in range(data.val_pos.size(1)):\n",
    "        val_graphs.append(plus_edge(data_observed,1,data.val_pos[:,i]))\n",
    "\n",
    "    for i in range(data.val_neg.size(1)):\n",
    "        val_graphs.append(plus_edge(data_observed,0,data.val_neg[:,i]))\n",
    "    '''\n",
    "    else:\n",
    "        for i in range(data.val_pos.size(1)):\n",
    "            val_graphs.append(minus_edge(data_observed,1,data.val_pos[:,i]))\n",
    "\n",
    "        for i in range(data.val_neg.size(1)):\n",
    "            val_graphs.append(plus_edge(data_observed,0,data.val_neg[:,i]))\n",
    "    '''\n",
    "\n",
    "    \n",
    "    print('Train_link:', str(len(train_graphs)),\n",
    "          ' Val_link:',str(len(val_graphs)),' Test_link:',str(len(test_graphs)))\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_graphs,batch_size=batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(val_graphs,batch_size=batch_size,shuffle=True)\n",
    "    test_loader = DataLoader(test_graphs,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader,feature_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b992a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive edges shape(train,val):"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'shapee'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18584\\1946655101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mContent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18584\\2282334340.py\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(content, train, test)\u001b[0m\n\u001b[0;32m     12\u001b[0m     data = Data(edge_index=edge_index,x=features.to(torch.float),\n\u001b[0;32m     13\u001b[0m                 pos = edge_index_pos,neg = edge_index_neg,test = edge_index_test)\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18584\\384259621.py\u001b[0m in \u001b[0;36msplit_edges\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Positive edges shape(train,val):\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#print(data.train_pos.shape,data.test_pos.shape,data.val_pos.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_pos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapee\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_pos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#split neg edges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'shapee'"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader,feature_results = prepare_data(Content,Train,Test)\n",
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = next(iter(train_loader)).x.size(1)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimention of features after concatenation:\",num_features)\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f69006",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f60c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPred(MessagePassing):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, heads: int = 1,\\\n",
    "                 walk_len: int = 6, drnl: bool = False, z_max: int =100, MSE: bool=True):\n",
    "        super(LinkPred, self).__init__()\n",
    "\n",
    "        self.drnl = drnl\n",
    "        if drnl == True:\n",
    "            self.z_embedding = Embedding(z_max, hidden_channels)\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.wp = WalkPooling(in_channels + hidden_channels*2,\\\n",
    "            hidden_channels, heads, walk_len)\n",
    "\n",
    "        L=walk_len*5+1\n",
    "        self.classifier = MLP(L*heads,MSE=MSE)\n",
    "        self.norm = nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_mask, batch, z = None):\n",
    "        \n",
    "        #using drnl\n",
    "        if self.drnl == True:\n",
    "            z_emb = self.z_embedding(z)\n",
    "            if z_emb.ndim == 3:  # in case z has multiple integer labels\n",
    "                z_emb = z_emb.sum(dim=1)\n",
    "            z_emb = z_emb.view(x.size(0),-1)\n",
    "            x = torch.cat((x,z_emb.view(x.size(0),-1)),dim=1)\n",
    "        \n",
    "        #GCN layers\n",
    "        x_out = x\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x_out = torch.cat((x_out,x),dim=1)\n",
    "        x = x.relu()\n",
    "        x = self.norm(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.norm(x)\n",
    "        x_out = torch.cat((x_out,x),dim=1)\n",
    "\n",
    "        #Walk Pooling\n",
    "        feature_list = self.wp(x_out, edge_index, edge_mask, batch)\n",
    "\n",
    "        #Classifier\n",
    "        out = self.classifier(feature_list)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class WalkPooling(MessagePassing):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, heads: int = 1,\\\n",
    "                 walk_len: int = 6):\n",
    "        super(WalkPooling, self).__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.heads = heads\n",
    "        self.walk_len = walk_len\n",
    "\n",
    "        # the linear layers in the attention encoder\n",
    "        self.lin_key1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin_query1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin_key2 = Linear(hidden_channels, heads * hidden_channels)\n",
    "        self.lin_query2 = Linear(hidden_channels, heads * hidden_channels)\n",
    "    def attention_mlp(self, x, edge_index):\n",
    "    \n",
    "        query = self.lin_key1(x).reshape(-1,self.hidden_channels)\n",
    "        key = self.lin_query1(x).reshape(-1,self.hidden_channels)\n",
    "\n",
    "        query = F.leaky_relu(query,0.2)\n",
    "        key = F.leaky_relu(key,0.2)\n",
    "\n",
    "        query = F.dropout(query, p=0.5, training=self.training)\n",
    "        key = F.dropout(key, p=0.5, training=self.training)\n",
    "\n",
    "        query = self.lin_key2(query).view(-1, self.heads, self.hidden_channels)\n",
    "        key = self.lin_query2(key).view(-1, self.heads, self.hidden_channels)\n",
    "\n",
    "        row, col = edge_index\n",
    "        weights = (query[row] * key[col]).sum(dim=-1) / np.sqrt(self.hidden_channels)\n",
    "        \n",
    "        return weights\n",
    "\n",
    "    def weight_encoder(self, x, edge_index, edge_mask):        \n",
    "     \n",
    "        weights = self.attention_mlp(x, edge_index)\n",
    "    \n",
    "        omega = torch.sigmoid(weights[torch.logical_not(edge_mask)])\n",
    "        \n",
    "        row, col = edge_index\n",
    "        num_nodes = torch.max(edge_index)+1\n",
    "\n",
    "        # edge weights of the plus graph\n",
    "        weights_p = softmax(weights,edge_index[1])\n",
    "\n",
    "        # edge weights of the minus graph\n",
    "        weights_m = weights - scatter_max(weights, col, dim=0, dim_size=num_nodes)[0][col]\n",
    "        weights_m = torch.exp(weights_m)\n",
    "        weights_m = weights_m * edge_mask.view(-1,1)\n",
    "        norm = scatter_add(weights_m, col, dim=0, dim_size=num_nodes)[col] + 1e-16\n",
    "        weights_m = weights_m / norm\n",
    "\n",
    "        return weights_p, weights_m, omega\n",
    "\n",
    "    def forward(self, x, edge_index, edge_mask, batch):\n",
    "        \n",
    "        #encode the node representation into edge weights via attention mechanism\n",
    "        weights_p, weights_m, omega = self.weight_encoder(x, edge_index, edge_mask)\n",
    "\n",
    "        # pytorch geometric set the batch adjacency matrix to\n",
    "        # be the diagonal matrix with each graph's adjacency matrix\n",
    "        # stacked in the diagonal. Therefore, calculating the powers\n",
    "        # of the stochastic matrix directly will cost lots of memory.\n",
    "        # We compute the powers of stochastic matrix as follows\n",
    "        # Let A = diag ([A_1,\\cdots,A_n]) be the batch adjacency matrix,\n",
    "        # we set x = [x_1,\\cdots,x_n]^T be the batch feature matrix\n",
    "        # for the i-th graph in the batch with n_i nodes, its feature \n",
    "        # is a n_i\\times n_max matrix, where n_max is the largest number\n",
    "        # of nodes for all graphs in the batch. The elements of x_i are\n",
    "        # (x_i)_{x,y} = \\delta_{x,y}. \n",
    "\n",
    "        # number of graphs in the batch\n",
    "        batch_size = torch.max(batch)+1\n",
    "\n",
    "        # for node i in the batched graph, index[i] is i's id in the graph before batch \n",
    "        index = torch.zeros(batch.size(0),1,dtype=torch.long)\n",
    "        \n",
    "        # numer of nodes in each graph\n",
    "        _, counts = torch.unique(batch, sorted=True, return_counts=True)\n",
    "        \n",
    "        # maximum number of nodes for all graphs in the batch\n",
    "        max_nodes = torch.max(counts)\n",
    "\n",
    "        # set the values in index\n",
    "        id_start = 0\n",
    "        for i in range(batch_size):\n",
    "            index[id_start:id_start+counts[i]] = torch.arange(0,counts[i],dtype=torch.long).view(-1,1)\n",
    "            id_start = id_start+counts[i]\n",
    "\n",
    "        index = index.to(device)\n",
    "        \n",
    "        #the output graph features of walk pooling\n",
    "        nodelevel_p = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        nodelevel_m = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        linklevel_p = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        linklevel_m = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        graphlevel = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        # a link (i,j) has two directions i->j and j->i, and\n",
    "        # when extract the features of the link, we usually average over\n",
    "        # the two directions. indices_odd and indices_even records the\n",
    "        # indices for a link in two directions\n",
    "        indices_odd = torch.arange(0,omega.size(0),2).to(device)\n",
    "        indices_even = torch.arange(1,omega.size(0),2).to(device)\n",
    "\n",
    "        omega = torch.index_select(omega, 0 ,indices_even)\\\n",
    "        + torch.index_select(omega,0,indices_odd)\n",
    "        \n",
    "        #node id of the candidate (or perturbation) link\n",
    "        link_ij, link_ji = edge_index[:,torch.logical_not(edge_mask)]\n",
    "        node_i = link_ij[indices_odd]\n",
    "        node_j = link_ij[indices_even]\n",
    "\n",
    "        # compute the powers of stochastic matrix\n",
    "        for head in range(self.heads):\n",
    "\n",
    "            # x on the plus graph and minus graph\n",
    "            x_p = torch.zeros(batch.size(0),max_nodes,dtype=x.dtype).to(device)\n",
    "            x_p = x_p.scatter_(1,index,1)\n",
    "            x_m = torch.zeros(batch.size(0),max_nodes,dtype=x.dtype).to(device)\n",
    "            x_m = x_m.scatter_(1,index,1)\n",
    "\n",
    "            # propagage once\n",
    "            x_p = self.propagate(edge_index, x= x_p, norm = weights_p[:,head])\n",
    "            x_m = self.propagate(edge_index, x= x_m, norm = weights_m[:,head])\n",
    "        \n",
    "            # start from tau = 2\n",
    "            for i in range(self.walk_len):\n",
    "                #print(f\"self.walk_len:{i}\")\n",
    "                x_p = self.propagate(edge_index, x= x_p, norm = weights_p[:,head])\n",
    "                x_m = self.propagate(edge_index, x= x_m, norm = weights_m[:,head])\n",
    "                \n",
    "                # returning probabilities around i + j\n",
    "                nodelevel_p_w = x_p[node_i,index[node_i].view(-1)] + x_p[node_j,index[node_j].view(-1)]\n",
    "                nodelevel_m_w = x_m[node_i,index[node_i].view(-1)] + x_m[node_j,index[node_j].view(-1)]\n",
    "                nodelevel_p[:,head*self.walk_len+i] = nodelevel_p_w.view(-1)\n",
    "                nodelevel_m[:,head*self.walk_len+i] = nodelevel_m_w.view(-1)\n",
    "  \n",
    "                # transition probabilities between i and j\n",
    "                linklevel_p_w = x_p[node_i,index[node_j].view(-1)] + x_p[node_j,index[node_i].view(-1)]\n",
    "                linklevel_m_w = x_m[node_i,index[node_j].view(-1)] + x_m[node_j,index[node_i].view(-1)]\n",
    "                linklevel_p[:,head*self.walk_len+i] = linklevel_p_w.view(-1)\n",
    "                linklevel_m[:,head*self.walk_len+i] = linklevel_m_w.view(-1)\n",
    "\n",
    "                # graph average of returning probabilities\n",
    "                diag_ele_p = torch.gather(x_p,1,index)\n",
    "                diag_ele_m = torch.gather(x_m,1,index)\n",
    "\n",
    "                graphlevel_p = scatter_add(diag_ele_p, batch, dim = 0)\n",
    "                graphlevel_m = scatter_add(diag_ele_m, batch, dim = 0)\n",
    "\n",
    "                graphlevel[:,head*self.walk_len+i] = (graphlevel_p-graphlevel_m).view(-1)\n",
    "         \n",
    "        feature_list = graphlevel \n",
    "        feature_list = torch.cat((feature_list,omega),dim=1)\n",
    "        feature_list = torch.cat((feature_list,nodelevel_p),dim=1)\n",
    "        feature_list = torch.cat((feature_list,nodelevel_m),dim=1)\n",
    "        feature_list = torch.cat((feature_list,linklevel_p),dim=1)\n",
    "        feature_list = torch.cat((feature_list,linklevel_m),dim=1)\n",
    "\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j  \n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    # adopt a MLP as classifier for graphs\n",
    "    def __init__(self,input_size,MSE=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.nn = nn.BatchNorm1d(input_size)\n",
    "        self.linear1 = torch.nn.Linear(input_size,input_size*20)\n",
    "        self.linear2 = torch.nn.Linear(input_size*20,input_size*20)\n",
    "        self.linear3 = torch.nn.Linear(input_size*20,input_size*10)\n",
    "        self.linear4 = torch.nn.Linear(input_size*10,input_size)\n",
    "        self.linear5 = torch.nn.Linear(input_size,1)\n",
    "        self.act= nn.ReLU()\n",
    "        self.MSE=MSE\n",
    "        self.norm1 = nn.BatchNorm1d(input_size*20)\n",
    "        self.norm2 = nn.BatchNorm1d(input_size*20)\n",
    "        self.norm3 = nn.BatchNorm1d(input_size*10)\n",
    "        self.norm4 = nn.BatchNorm1d(input_size)\n",
    "    def forward(self, x):\n",
    "        out= self.nn(x)\n",
    "        out= self.linear1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm1(out)\n",
    "        out= self.linear2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm3(out)\n",
    "        out = self.linear4(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm4(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.linear5(out)\n",
    "        #out = torch.sigmoid(out)\n",
    "        if self.MSE:\n",
    "            out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fdb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader,epoch):\n",
    "    model.train()\n",
    "    loss_epoch=0\n",
    "    for data in tqdm(loader,desc=\"train\"):  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        label= data.label\n",
    "        out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "        torch.cuda.empty_cache()\n",
    "        loss = criterion(out.view(-1), label)  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        loss_epoch=loss_epoch+loss.item()\n",
    "    return loss_epoch/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ac7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader,data_type='test'):\n",
    "    model.eval()\n",
    "    scores = torch.tensor([])\n",
    "    labels = torch.tensor([])\n",
    "    loss_total=0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader,desc='test:'+data_type):  # Iterate in batches over the training/test dataset.\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "            loss = criterion(out.view(-1), data.label)\n",
    "            out = out.cpu().clone().detach()\n",
    "            scores = torch.cat((scores,out),dim = 0)\n",
    "            labels = torch.cat((labels,data.label.view(-1,1).cpu().clone().detach()),dim = 0)\n",
    "        scores = scores.cpu().clone().detach().numpy()\n",
    "        labels = labels.cpu().clone().detach().numpy()\n",
    "        loss_total=loss_total+loss.item()\n",
    "        return roc_auc_score(labels, scores), average_precision_score(labels, scores),loss_total,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_len = 10\n",
    "lr = 0.005\n",
    "heads = 5\n",
    "hidden_channels = 128\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "z_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkPred(in_channels = num_features, hidden_channels = hidden_channels,\\\n",
    "    heads = heads, walk_len = walk_len, drnl = False,z_max = z_max, MSE= True).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=0)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "#criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7785b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Best_Val_fromloss=1e10\n",
    "Final_Test_AUC_fromloss=0\n",
    "Final_Test_AP_fromloss=0\n",
    "\n",
    "Best_Val_fromAUC=0\n",
    "Final_Test_AUC_fromAUC=0\n",
    "Final_Test_AP_fromAUC=0\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    loss_epoch = train(train_loader,epoch)\n",
    "    val_auc, val_ap, val_loss,_ = test(val_loader,data_type='val')\n",
    "    #test_auc,test_ap,_,_ = test(test_loader,data_type='test')\n",
    "    if val_loss < Best_Val_fromloss:\n",
    "        Best_Val_fromloss = val_loss\n",
    "        #Final_Test_AUC_fromloss = test_auc\n",
    "        #Final_Test_AP_fromloss = test_ap\n",
    "\n",
    "    if val_auc > Best_Val_fromAUC:\n",
    "        Best_Val_fromAUC = val_auc\n",
    "        #Final_Test_AUC_fromAUC = test_auc\n",
    "        #Final_Test_AP_fromAUC = test_ap\n",
    "    print(f'Epoch: {epoch:03d}, Loss : {loss_epoch:.4f},\\\n",
    "     Val Loss : {val_loss:.4f}, Val AUC: {val_auc:.4f}')\n",
    "    '''\n",
    "    print(f'Epoch: {epoch:03d}, Loss : {loss_epoch:.4f},\\\n",
    "     Val Loss : {val_loss:.4f}, Val AUC: {val_auc:.4f},\\\n",
    "      Test AUC: {test_auc:.4f}, Picked AUC:{Final_Test_AUC_fromAUC:.4f}')\n",
    "print(f'From loss: Final Test AUC: {Final_Test_AUC_fromloss:.4f}, Final Test AP: {Final_Test_AP_fromloss:.4f}')\n",
    "print(f'From AUC: Final Test AUC: {Final_Test_AUC_fromAUC:.4f}, Final Test AP: {Final_Test_AP_fromAUC:.4f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96010c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "scores = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "loss_total=0\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader,desc='test:'):  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "        out = out.cpu().clone().detach()\n",
    "        scores = torch.cat((scores,out),dim = 0)\n",
    "    scores = scores.cpu().clone().detach().numpy()\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upload['prob'] = scores.flatten().astype('float64')\n",
    "Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe62b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upload.to_csv('output/1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68337e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
