{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2df931a",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bdc5e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_undirected, from_scipy_sparse_matrix,dense_to_sparse,is_undirected\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import softmax\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Parameter,Embedding\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_mean, scatter, scatter_add, scatter_max\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27941b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E370</td>\n",
       "      <td>26</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E667</td>\n",
       "      <td>196</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3190</td>\n",
       "      <td>739</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E848</td>\n",
       "      <td>576</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2161</td>\n",
       "      <td>466</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   to  from\n",
       "0   E370   26   317\n",
       "1   E667  196   323\n",
       "2  E3190  739   468\n",
       "3   E848  576   156\n",
       "4  E2161  466   199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"hw2_data/\"\n",
    "dss = ['dataset1','dataset2','dataset3'] #datasets\n",
    "dataset = dict()\n",
    "for ds in dss:\n",
    "    dataset[ds] = dict()\n",
    "    dataset[ds]['content'] = pd.read_csv(path+ds+\"/content.csv\",delimiter = '\\t',header = None)\n",
    "    dataset[ds]['train'] = pd.read_csv(path+ds+\"/train.csv\",delimiter = ',')\n",
    "    dataset[ds]['test'] = pd.read_csv(path+ds+\"/test.csv\",delimiter = ',')\n",
    "    dataset[ds]['upload'] = pd.read_csv(path+ds+\"/upload.csv\",delimiter = ',')\n",
    "dataset[dss[2]]['test'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0da49",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222d51e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 1434)\n",
      "2708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1433,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[dss[0]]['content'].shape)\n",
    "print(len(dataset[dss[0]]['content']))\n",
    "np.array(dataset[dss[0]]['content'].iloc[0,1:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2563c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8686, 4)\n",
      "8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2397"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[dss[0]]['train'].shape)\n",
    "print(len(dataset[dss[0]]['train']))\n",
    "dataset[dss[0]]['train'].loc[1,'to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c400784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edge(0,1,label=0)\n",
    "G.add_edge(0,2,label=1)\n",
    "G.add_edge(1,2,label=1)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b7b149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2, 1), (1, 2, 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in list(G.edges.data('label')) if e[2]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6401abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example:\n",
    "Content = dataset[dss[0]]['content']\n",
    "Train = dataset[dss[0]]['train']\n",
    "Test = dataset[dss[0]]['test']\n",
    "Upload = dataset[dss[0]]['upload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbb0319c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1434)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af37fe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E10087</td>\n",
       "      <td>1767</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>E2206</td>\n",
       "      <td>2062</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>E783</td>\n",
       "      <td>455</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>E1142</td>\n",
       "      <td>1547</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    to  from  label\n",
       "14    E10087  1767     4      1\n",
       "1698   E2206  2062     4      1\n",
       "5178    E783   455     4      0\n",
       "5845   E1142  1547     4      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[Train['from']==4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b5e9f",
   "metadata": {},
   "source": [
    "---\n",
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3980e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da085f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd7d9e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9327be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor(x):\n",
    "    return torch.div(x, 1, rounding_mode='trunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44349bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(features):\n",
    "    # Row-normalize feature matrix and convert to tuple representation\n",
    "    # Because the datasets only have binary features, row-normalize is unnecessary\n",
    "    rowsum = np.array(features.sum(1),dtype = np.float32)\n",
    "    rowsum = (rowsum==0)*1+rowsum\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d2e8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(content,train, test):\n",
    "    G = nx.DiGraph()\n",
    "    # for easier split the edges, create 2 graph, 1 with positive edge, the other with given negative edges\n",
    "    G_pos = nx.DiGraph()\n",
    "    G_neg = nx.DiGraph()\n",
    "    graph_node_features_dict = dict()\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        #graph_node_features_dict[content.iloc[i,0]] = np.array(content.iloc[i,1:])\n",
    "        G.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        # pos and neg\n",
    "        G_pos.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        G_neg.add_node(int(content.iloc[i,0]),features = np.array(content.iloc[i,1:]))\n",
    "        \n",
    "    for i in range(len(train)):\n",
    "        # Adding nodes into G\n",
    "        '''\n",
    "        if train.loc[i,'from'] not in G:\n",
    "            G.add_node(train.loc[i,'from'],features = graph_node_features_dict[train.loc[i,'from']])\n",
    "        if train.loc[i,'to'] not in G:\n",
    "            G.add_node(train.loc[i,'to'],features = graph_node_features_dict[train.loc[i,'to']])\n",
    "        ''' \n",
    "        # Adding edges\n",
    "        G.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "        \n",
    "        # pos and neg\n",
    "        if train.loc[i,'label'] == 0: \n",
    "            G_neg.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "        else:\n",
    "            G_pos.add_edge(train.loc[i,'from'],train.loc[i,'to'],label = train.loc[i,'label'])\n",
    "\n",
    "    adj = nx.adjacency_matrix(G,sorted(G.nodes()))\n",
    "    adj_pos = nx.adjacency_matrix(G_pos,sorted(G_pos.nodes()))\n",
    "    adj_neg = nx.adjacency_matrix(G_neg,sorted(G_neg.nodes()))\n",
    "    features = np.array(\n",
    "        [features for _, features in sorted(G.nodes(data='features'), key=lambda x: x[0])])\n",
    "    \n",
    "    # Skip train,valid,and test mask\n",
    "    \n",
    "    num_features = features.shape[1]\n",
    "    features = torch.FloatTensor(features)\n",
    "    return adj, adj_pos, adj_neg, features, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e6b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, pos, neg, features, num_features = load_data(Content,Train,Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a433235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edges(data):\n",
    "    set_random_seed(10) #Seed is randomly set\n",
    "    \n",
    "    # ? This select the edges that from<to, but why? Don't understand, not using this\n",
    "    row, col = data.edge_index\n",
    "    mask = row < col\n",
    "    row, col = row[mask], col[mask]\n",
    "    \n",
    "    val_ratio = 0.1\n",
    "    #test_ratio = 0.1\n",
    "    \n",
    "    #split positive edges\n",
    "    row_pos, col_pos = data.pos\n",
    "    mask_pos = row_pos < col_pos\n",
    "    row_pos, col_pos = row_pos[mask_pos], col_pos[mask_pos]\n",
    "\n",
    "    n_v = floor(val_ratio * row_pos.size(0)).int() #number of validation positive edges\n",
    "    #n_t = floor(test_ratio * row_pos.size(0)).int() #number of test positive edges\n",
    "    \n",
    "    perm = torch.randperm(row_pos.size(0))\n",
    "    row_pos, col_pos = row_pos[perm], col_pos[perm]\n",
    "    r, c = row_pos[:n_v], col_pos[:n_v]\n",
    "    data.val_pos = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_pos[n_v:n_v+n_t], col_pos[n_v:n_v+n_t]\n",
    "    #data.test_pos = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_pos[n_v+n_t:], col_pos[n_v+n_t:]\n",
    "    r, c = row_pos[n_v:], col_pos[n_v:]\n",
    "    data.train_pos = torch.stack([r, c], dim=0)\n",
    "    print(\"Positive edges shape(train,val):\",end=\"\")\n",
    "    #print(data.train_pos.shape,data.test_pos.shape,data.val_pos.shape)\n",
    "    print(data.train_pos.shape,data.val_pos.shape)\n",
    "    \n",
    "    #split neg edges\n",
    "    row_neg, col_neg = data.neg\n",
    "    mask_neg = row_neg < col_neg\n",
    "    row_neg, col_neg = row_neg[mask_neg], col_neg[mask_neg]\n",
    "    \n",
    "    \n",
    "    n_v = floor(val_ratio * row_neg.size(0)).int() #number of validation positive edges\n",
    "    #n_t = floor(test_ratio * row_neg.size(0)).int() #number of test positive edges\n",
    "    \n",
    "    perm = torch.randperm(row_neg.size(0))\n",
    "    row_neg, col_neg = row_neg[perm], col_neg[perm]\n",
    "    r, c = row_neg[:n_v], col_neg[:n_v]\n",
    "    data.val_neg = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_neg[n_v:n_v+n_t], col_neg[n_v:n_v+n_t]\n",
    "    #data.test_neg = torch.stack([r, c], dim=0)\n",
    "    #r, c = row_neg[n_v+n_t:], col_neg[n_v+n_t:]\n",
    "    r, c = row_neg[n_v:], col_neg[n_v:]\n",
    "    data.train_neg = torch.stack([r, c], dim=0)\n",
    "    print(\"Negative edges shape(train,val):\",end=\"\")\n",
    "    #print(data.train_neg.shape,data.test_neg.shape,data.val_neg.shape)\n",
    "    print(data.train_neg.shape,data.val_neg.shape)\n",
    "\n",
    "    #costruct real test edges\n",
    "    row_test,col_test = data.test\n",
    "    data.test = torch.stack([row_test,col_test],dim = 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bebf0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_init_attribute_representation(data):\n",
    "    # Construct data_observed and compute its node attributes & representation\n",
    "    # Why create undirected edge? Don't use this\n",
    "    # Now pretend args.observe_val_and_injection = False\n",
    "    #print('Here')\n",
    "    #print(data.train_pos.shape,data.train_pos[[1,0],:].shape)\n",
    "    #print(data.train_pos,data.train_pos[[1,0],:])\n",
    "    #print(data.train_pos[:,:],,data.train_pos[[1,0],:])\n",
    "    edge_index = torch.cat((data.train_pos,data.train_pos[[1,0],:]),dim=1)\n",
    "    #print(edge_index)\n",
    "    #edge_index = data.train_pos\n",
    "    #edge_index=torch.cat((edge_index,data.val_pos,data.val_pos[[1,0],:]),dim=1)\n",
    "    data_observed = Data(edge_index=edge_index)\n",
    "    data_observed.num_nodes = data.num_nodes\n",
    "    #use the injection trick and add val data in observed graph \n",
    "    #edge_index_observed = torch.cat((data_observed.edge_index,\\\n",
    "    #    data.train_neg,data.train_neg[[1,0],:],data.val_neg,data.val_neg[[1,0],:]),dim=1)\n",
    "    edge_index_observed = data_observed.edge_index\n",
    "  \n",
    "    #generate the initial node attribute if there isn't any\n",
    "    init_attribute = 'n2v' # Can choose between 'n2v','one_hot','spc','ones','zeros',\n",
    "    # But we already prepare features so it doesn't matter\n",
    "    if data.x == None:\n",
    "        if init_attribute =='n2v':\n",
    "            from node2vec import CalN2V\n",
    "            x = CalN2V(edge_index_observed)#,args)\n",
    "        if init_attribute =='one_hot':\n",
    "            x = F.one_hot(torch.arange(data.num_nodes), num_classes=data.num_nodes)\n",
    "            x = x.float()\n",
    "        if init_attribute =='spc':\n",
    "            from SPC import spc\n",
    "            x = spc(edge_index_observed)#,args)\n",
    "            x = x.float()\n",
    "        if init_attribute =='ones':\n",
    "            embedding_dim = 32\n",
    "            x = torch.ones(data.num_nodes,args.embedding_dim)\n",
    "            x = x.float()\n",
    "        if init_attribute =='zeros':\n",
    "            embedding_dim = 32\n",
    "            x = torch.zeros(data.num_nodes,args.embedding_dim)\n",
    "            x = x.float()\n",
    "    else:\n",
    "        x = data.x\n",
    "    #generate the initial node representation using unsupervised models\n",
    "    \n",
    "    init_representation = None # Don't understand what this part doing\n",
    "    if init_representation != None:\n",
    "        val_and_test=[data.test_pos,data.test_neg,data.val_pos,data.val_neg]\n",
    "        num_nodes,_=x.shape\n",
    "        #add self-loop for the last node to aviod losing node if the last node dosen't have a link.\n",
    "        if (num_nodes-1) in edge_index_observed:\n",
    "            edge_index_observed=edge_index_observed.clone().detach()\n",
    "        else:\n",
    "            edge_index_observed=torch.cat((edge_index_observed.clone().detach(),torch.tensor([[num_nodes-1],[num_nodes-1]])),dim=1)\n",
    "        if init_representation == 'gic':\n",
    "            par_dir = os.path.abspath(os.path.join(os.path.dirname(__file__),\"..\"))\n",
    "            sys.path.append('%s/software/GIC/' % args.par_dir)\n",
    "            from GICEmbs import CalGIC\n",
    "            data_observed.x, auc, ap = CalGIC(edge_index_observed, x, args.data_name, val_and_test,args)\n",
    "\n",
    "        if init_representation == 'vgae':\n",
    "            from vgae import CalVGAE\n",
    "            data_observed.x, auc, ap = CalVGAE(edge_index_observed, x, val_and_test, args)\n",
    "        if init_representation == 'svgae':\n",
    "            from svgae import CalSVGAE\n",
    "            data_observed.x, auc, ap = CalSVGAE(edge_index_observed, x, val_and_test, args)\n",
    "        if init_representation == 'argva':\n",
    "            from argva import CalARGVA\n",
    "            data_observed.x, auc, ap = CalARGVA(edge_index_observed, x, val_and_test, args)\n",
    "        feature_results=[auc,ap]\n",
    "    else:\n",
    "        data_observed.x = x\n",
    "        feature_results=None\n",
    "\n",
    "    return data_observed,feature_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce585441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_hop_subgraph(node_idx, num_hops, edge_index, max_nodes_per_hop = None,num_nodes = None):\n",
    "  \n",
    "    if num_nodes == None:\n",
    "        num_nodes = torch.max(edge_index)+1\n",
    "    row, col = edge_index\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    node_idx = node_idx.to(row.device)\n",
    "\n",
    "    subsets = [node_idx]\n",
    "\n",
    "    if max_nodes_per_hop == None:\n",
    "        for _ in range(num_hops):\n",
    "            node_mask.fill_(False)\n",
    "            node_mask[subsets[-1]] = True\n",
    "            torch.index_select(node_mask, 0, row, out = edge_mask)\n",
    "            subsets.append(col[edge_mask])\n",
    "    else:\n",
    "        not_visited = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "        not_visited.fill_(True)\n",
    "        for _ in range(num_hops):\n",
    "            node_mask.fill_(False)# the source node mask in this hop\n",
    "            node_mask[subsets[-1]] = True #mark the sources\n",
    "            not_visited[subsets[-1]] = False # mark visited nodes\n",
    "            torch.index_select(node_mask, 0, row, out = edge_mask) # indices of all neighbors\n",
    "            neighbors = col[edge_mask].unique() #remove repeats\n",
    "            neighbor_mask = row.new_empty(num_nodes, dtype=torch.bool) # mask of all neighbor nodes\n",
    "            edge_mask_hop = row.new_empty(row.size(0), dtype=torch.bool) # selected neighbor mask in this hop\n",
    "            neighbor_mask.fill_(False)\n",
    "            neighbor_mask[neighbors] = True\n",
    "            neighbor_mask = torch.logical_and(neighbor_mask, not_visited) # all neighbors that are not visited\n",
    "            ind = torch.where(neighbor_mask==True) #indicies of all the unvisited neighbors\n",
    "            if ind[0].size(0) > max_nodes_per_hop:\n",
    "                perm = torch.randperm(ind[0].size(0))\n",
    "                ind = ind[0][perm]\n",
    "                neighbor_mask[ind[max_nodes_per_hop:]] = False # randomly select max_nodes_per_hop nodes\n",
    "                torch.index_select(neighbor_mask, 0, col, out = edge_mask_hop)# find the indicies of selected nodes\n",
    "                edge_mask = torch.logical_and(edge_mask,edge_mask_hop) # change edge_mask\n",
    "            subsets.append(col[edge_mask])\n",
    "\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "    inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    node_idx = row.new_full((num_nodes, ), -1)\n",
    "    node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "    edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, inv, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac382c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus_edge(data_observed, label, p_edge):\n",
    "    num_hops = 4 # number of hops in sampling subgraph, set 2 which same as default\n",
    "    max_nodes_per_hop =  None #when the graph is too large or too dense, \n",
    "    #we need max node per hop threshold to avoid OOM. Default is None\n",
    "    nodes, edge_index_m, mapping, _ = k_hop_subgraph(node_idx= p_edge, num_hops= num_hops,\\\n",
    " edge_index = data_observed.edge_index, max_nodes_per_hop= max_nodes_per_hop ,num_nodes=data_observed.num_nodes)\n",
    "    x_sub = data_observed.x[nodes,:]\n",
    "    edge_index_p = edge_index_m\n",
    "    edge_index_p = torch.cat((edge_index_p, mapping.view(-1,1)),dim=1)\n",
    "    edge_index_p = torch.cat((edge_index_p, mapping[[1,0]].view(-1,1)),dim=1)\n",
    "\n",
    "    #edge_mask marks the edge under perturbation, i.e., the candidate edge for LP\n",
    "    edge_mask = torch.ones(edge_index_p.size(1),dtype=torch.bool)\n",
    "    edge_mask[-1] = False\n",
    "    edge_mask[-2] = False\n",
    "    \n",
    "    '''\n",
    "    # Run here for drnl labeling\n",
    "    if drnl == True:\n",
    "        num_nodes = torch.max(edge_index_p)+1\n",
    "        z = drnl_node_labeling(edge_index_m, mapping[0],mapping[1],num_nodes)\n",
    "        data = Data(edge_index = edge_index_p, x = x_sub, z = z)\n",
    "    '''\n",
    "    data = Data(edge_index = edge_index_p, x = x_sub, z = 0)\n",
    "    data.edge_mask = edge_mask\n",
    "\n",
    "    #label = 1 if the candidate link (p_edge) is positive and label=0 otherwise\n",
    "    data.label = float(label)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59e2764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_edge(data_observed, label, p_edge):\n",
    "    num_hops = 2 # number of hops in sampling subgraph, set 2 which same as default\n",
    "    max_nodes_per_hop =  None #when the graph is too large or too dense, \n",
    "    #we need max node per hop threshold to avoid OOM. Default is None\n",
    "    \n",
    "    nodes, edge_index_p, mapping,_ = k_hop_subgraph(node_idx= p_edge, num_hops=num_hops,\\\n",
    " edge_index = data_observed.edge_index,max_nodes_per_hop=max_nodes_per_hop, num_nodes = data_observed.num_nodes)\n",
    "    x_sub = data_observed.x[nodes,:]\n",
    "\n",
    "    #edge_mask marks the edge under perturbation, i.e., the candidate edge for LP\n",
    "    edge_mask = torch.ones(edge_index_p.size(1), dtype = torch.bool)\n",
    "    ind = torch.where((edge_index_p == mapping.view(-1,1)).all(dim=0))\n",
    "    edge_mask[ind[0]] = False\n",
    "    ind = torch.where((edge_index_p == mapping[[1,0]].view(-1,1)).all(dim=0))\n",
    "    edge_mask[ind[0]] = False\n",
    "    '''\n",
    "    if args.drnl == True:\n",
    "        num_nodes = torch.max(edge_index_p)+1\n",
    "        z = drnl_node_labeling(edge_index_p[:,edge_mask], mapping[0],mapping[1],num_nodes)\n",
    "        data = Data(edge_index = edge_index_p, x= x_sub,z = z)\n",
    "    else:\n",
    "    '''\n",
    "    data = Data(edge_index = edge_index_p, x= x_sub,z = 0)\n",
    "    data.edge_mask = edge_mask\n",
    "\n",
    "    #label = 1 if the candidate link (p_edge) is positive and label=0 otherwise\n",
    "    data.label = float(label)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbe9c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "def prepare_data(content,train,test):\n",
    "    g, pos, neg, features, num_features = load_data(content,train,test)\n",
    "    A = g.toarray()\n",
    "    edge_index,_ = dense_to_sparse(torch.tensor(A))\n",
    "    Apos = pos.toarray()\n",
    "    edge_index_pos,_ = dense_to_sparse(torch.tensor(Apos))\n",
    "    Aneg = neg.toarray()\n",
    "    edge_index_neg,_ = dense_to_sparse(torch.tensor(Aneg))\n",
    "    data = Data(edge_index=edge_index,x=features.to(torch.float),\n",
    "                pos = edge_index_pos,neg = edge_index_neg,test = torch.tensor([Test['from'],Test['to']]))\n",
    "    data = split_edges(data)\n",
    "    \n",
    "\n",
    "    set_random_seed(42) # Random set the seed\n",
    "    data_observed,feature_results= set_init_attribute_representation(data)\n",
    "    # Construct train, val and test data loader\n",
    "    set_random_seed(42)\n",
    "    train_graphs = []\n",
    "    val_graphs = []\n",
    "    test_graphs = []\n",
    "    for i in range(data.train_pos.size(1)):\n",
    "        train_graphs.append(minus_edge(data_observed,1,data.train_pos[:,i]))\n",
    "\n",
    "    for i in range(data.train_neg.size(1)):\n",
    "        train_graphs.append(plus_edge(data_observed,0,data.train_neg[:,i]))\n",
    "    '''\n",
    "    for i in range(data.test_pos.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,1,data.test_pos[:,i]))\n",
    "\n",
    "    for i in range(data.test_neg.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,0,data.test_neg[:,i]))   \n",
    "    '''\n",
    "    for i in range(data.test.size(1)):\n",
    "        test_graphs.append(plus_edge(data_observed,1,data.test[:,i]))\n",
    "    \n",
    "    #if args.observe_val_and_injection == False:\n",
    "    # pretend args.observe_val_and_injection == False\n",
    "    for i in range(data.val_pos.size(1)):\n",
    "        val_graphs.append(plus_edge(data_observed,1,data.val_pos[:,i]))\n",
    "\n",
    "    for i in range(data.val_neg.size(1)):\n",
    "        val_graphs.append(plus_edge(data_observed,0,data.val_neg[:,i]))\n",
    "    '''\n",
    "    else:\n",
    "        for i in range(data.val_pos.size(1)):\n",
    "            val_graphs.append(minus_edge(data_observed,1,data.val_pos[:,i]))\n",
    "\n",
    "        for i in range(data.val_neg.size(1)):\n",
    "            val_graphs.append(plus_edge(data_observed,0,data.val_neg[:,i]))\n",
    "    '''\n",
    "\n",
    "    \n",
    "    print('Train_link:', str(len(train_graphs)),\n",
    "          ' Val_link:',str(len(val_graphs)),' Test_link:',str(len(test_graphs)))\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_graphs,batch_size=batch_size,shuffle=True)\n",
    "    val_loader = DataLoader(val_graphs,batch_size=batch_size,shuffle=True)\n",
    "    test_loader = DataLoader(test_graphs,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader,feature_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b992a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive edges shape(train,val):torch.Size([2, 1945]) torch.Size([2, 216])\n",
      "Negative edges shape(train,val):torch.Size([2, 1882]) torch.Size([2, 209])\n",
      "Train_link: 3827  Val_link: 425  Test_link: 2172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0x163333eaa48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader,feature_results = prepare_data(Content,Train,Test)\n",
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c71d7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d59a72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = next(iter(train_loader)).x.size(1)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dd565f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimention of features after concatenation: 1433\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimention of features after concatenation:\",num_features)\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e3351",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeb948f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3995fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPred(MessagePassing):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, heads: int = 1,\\\n",
    "                 walk_len: int = 6, drnl: bool = False, z_max: int =100, MSE: bool=True):\n",
    "        super(LinkPred, self).__init__()\n",
    "\n",
    "        self.drnl = drnl\n",
    "        if drnl == True:\n",
    "            self.z_embedding = Embedding(z_max, hidden_channels)\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.wp = WalkPooling(in_channels + hidden_channels*2,\\\n",
    "            hidden_channels, heads, walk_len)\n",
    "\n",
    "        L=walk_len*5+1\n",
    "        self.classifier = MLP(L*heads,MSE=MSE)\n",
    "        self.norm = nn.BatchNorm1d(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_mask, batch, z = None):\n",
    "        \n",
    "        #using drnl\n",
    "        if self.drnl == True:\n",
    "            z_emb = self.z_embedding(z)\n",
    "            if z_emb.ndim == 3:  # in case z has multiple integer labels\n",
    "                z_emb = z_emb.sum(dim=1)\n",
    "            z_emb = z_emb.view(x.size(0),-1)\n",
    "            x = torch.cat((x,z_emb.view(x.size(0),-1)),dim=1)\n",
    "        \n",
    "        #GCN layers\n",
    "        x_out = x\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x_out = torch.cat((x_out,x),dim=1)\n",
    "        x = x.relu()\n",
    "        x = self.norm(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.norm(x)\n",
    "        x_out = torch.cat((x_out,x),dim=1)\n",
    "\n",
    "        #Walk Pooling\n",
    "        feature_list = self.wp(x_out, edge_index, edge_mask, batch)\n",
    "\n",
    "        #Classifier\n",
    "        out = self.classifier(feature_list)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class WalkPooling(MessagePassing):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, heads: int = 1,\\\n",
    "                 walk_len: int = 6):\n",
    "        super(WalkPooling, self).__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.heads = heads\n",
    "        self.walk_len = walk_len\n",
    "\n",
    "        # the linear layers in the attention encoder\n",
    "        self.lin_key1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin_query1 = Linear(in_channels, hidden_channels)\n",
    "        self.lin_key2 = Linear(hidden_channels, heads * hidden_channels)\n",
    "        self.lin_query2 = Linear(hidden_channels, heads * hidden_channels)\n",
    "    def attention_mlp(self, x, edge_index):\n",
    "    \n",
    "        query = self.lin_key1(x).reshape(-1,self.hidden_channels)\n",
    "        key = self.lin_query1(x).reshape(-1,self.hidden_channels)\n",
    "\n",
    "        query = F.leaky_relu(query,0.2)\n",
    "        key = F.leaky_relu(key,0.2)\n",
    "\n",
    "        query = F.dropout(query, p=0.5, training=self.training)\n",
    "        key = F.dropout(key, p=0.5, training=self.training)\n",
    "\n",
    "        query = self.lin_key2(query).view(-1, self.heads, self.hidden_channels)\n",
    "        key = self.lin_query2(key).view(-1, self.heads, self.hidden_channels)\n",
    "\n",
    "        row, col = edge_index\n",
    "        weights = (query[row] * key[col]).sum(dim=-1) / np.sqrt(self.hidden_channels)\n",
    "        \n",
    "        return weights\n",
    "\n",
    "    def weight_encoder(self, x, edge_index, edge_mask):        \n",
    "     \n",
    "        weights = self.attention_mlp(x, edge_index)\n",
    "    \n",
    "        omega = torch.sigmoid(weights[torch.logical_not(edge_mask)])\n",
    "        \n",
    "        row, col = edge_index\n",
    "        num_nodes = torch.max(edge_index)+1\n",
    "\n",
    "        # edge weights of the plus graph\n",
    "        weights_p = softmax(weights,edge_index[1])\n",
    "\n",
    "        # edge weights of the minus graph\n",
    "        weights_m = weights - scatter_max(weights, col, dim=0, dim_size=num_nodes)[0][col]\n",
    "        weights_m = torch.exp(weights_m)\n",
    "        weights_m = weights_m * edge_mask.view(-1,1)\n",
    "        norm = scatter_add(weights_m, col, dim=0, dim_size=num_nodes)[col] + 1e-16\n",
    "        weights_m = weights_m / norm\n",
    "\n",
    "        return weights_p, weights_m, omega\n",
    "\n",
    "    def forward(self, x, edge_index, edge_mask, batch):\n",
    "        \n",
    "        #encode the node representation into edge weights via attention mechanism\n",
    "        weights_p, weights_m, omega = self.weight_encoder(x, edge_index, edge_mask)\n",
    "\n",
    "        # pytorch geometric set the batch adjacency matrix to\n",
    "        # be the diagonal matrix with each graph's adjacency matrix\n",
    "        # stacked in the diagonal. Therefore, calculating the powers\n",
    "        # of the stochastic matrix directly will cost lots of memory.\n",
    "        # We compute the powers of stochastic matrix as follows\n",
    "        # Let A = diag ([A_1,\\cdots,A_n]) be the batch adjacency matrix,\n",
    "        # we set x = [x_1,\\cdots,x_n]^T be the batch feature matrix\n",
    "        # for the i-th graph in the batch with n_i nodes, its feature \n",
    "        # is a n_i\\times n_max matrix, where n_max is the largest number\n",
    "        # of nodes for all graphs in the batch. The elements of x_i are\n",
    "        # (x_i)_{x,y} = \\delta_{x,y}. \n",
    "\n",
    "        # number of graphs in the batch\n",
    "        batch_size = torch.max(batch)+1\n",
    "\n",
    "        # for node i in the batched graph, index[i] is i's id in the graph before batch \n",
    "        index = torch.zeros(batch.size(0),1,dtype=torch.long)\n",
    "        \n",
    "        # numer of nodes in each graph\n",
    "        _, counts = torch.unique(batch, sorted=True, return_counts=True)\n",
    "        \n",
    "        # maximum number of nodes for all graphs in the batch\n",
    "        max_nodes = torch.max(counts)\n",
    "\n",
    "        # set the values in index\n",
    "        id_start = 0\n",
    "        for i in range(batch_size):\n",
    "            index[id_start:id_start+counts[i]] = torch.arange(0,counts[i],dtype=torch.long).view(-1,1)\n",
    "            id_start = id_start+counts[i]\n",
    "\n",
    "        index = index.to(device)\n",
    "        \n",
    "        #the output graph features of walk pooling\n",
    "        nodelevel_p = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        nodelevel_m = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        linklevel_p = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        linklevel_m = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        graphlevel = torch.zeros(batch_size,(self.walk_len*self.heads)).to(device)\n",
    "        # a link (i,j) has two directions i->j and j->i, and\n",
    "        # when extract the features of the link, we usually average over\n",
    "        # the two directions. indices_odd and indices_even records the\n",
    "        # indices for a link in two directions\n",
    "        indices_odd = torch.arange(0,omega.size(0),2).to(device)\n",
    "        indices_even = torch.arange(1,omega.size(0),2).to(device)\n",
    "\n",
    "        omega = torch.index_select(omega, 0 ,indices_even)\\\n",
    "        + torch.index_select(omega,0,indices_odd)\n",
    "        \n",
    "        #node id of the candidate (or perturbation) link\n",
    "        link_ij, link_ji = edge_index[:,torch.logical_not(edge_mask)]\n",
    "        node_i = link_ij[indices_odd]\n",
    "        node_j = link_ij[indices_even]\n",
    "\n",
    "        # compute the powers of stochastic matrix\n",
    "        for head in range(self.heads):\n",
    "\n",
    "            # x on the plus graph and minus graph\n",
    "            x_p = torch.zeros(batch.size(0),max_nodes,dtype=x.dtype).to(device)\n",
    "            x_p = x_p.scatter_(1,index,1)\n",
    "            x_m = torch.zeros(batch.size(0),max_nodes,dtype=x.dtype).to(device)\n",
    "            x_m = x_m.scatter_(1,index,1)\n",
    "\n",
    "            # propagage once\n",
    "            x_p = self.propagate(edge_index, x= x_p, norm = weights_p[:,head])\n",
    "            x_m = self.propagate(edge_index, x= x_m, norm = weights_m[:,head])\n",
    "        \n",
    "            # start from tau = 2\n",
    "            for i in range(self.walk_len):\n",
    "                #print(f\"self.walk_len:{i}\")\n",
    "                x_p = self.propagate(edge_index, x= x_p, norm = weights_p[:,head])\n",
    "                x_m = self.propagate(edge_index, x= x_m, norm = weights_m[:,head])\n",
    "                \n",
    "                # returning probabilities around i + j\n",
    "                nodelevel_p_w = x_p[node_i,index[node_i].view(-1)] + x_p[node_j,index[node_j].view(-1)]\n",
    "                nodelevel_m_w = x_m[node_i,index[node_i].view(-1)] + x_m[node_j,index[node_j].view(-1)]\n",
    "                nodelevel_p[:,head*self.walk_len+i] = nodelevel_p_w.view(-1)\n",
    "                nodelevel_m[:,head*self.walk_len+i] = nodelevel_m_w.view(-1)\n",
    "  \n",
    "                # transition probabilities between i and j\n",
    "                linklevel_p_w = x_p[node_i,index[node_j].view(-1)] + x_p[node_j,index[node_i].view(-1)]\n",
    "                linklevel_m_w = x_m[node_i,index[node_j].view(-1)] + x_m[node_j,index[node_i].view(-1)]\n",
    "                linklevel_p[:,head*self.walk_len+i] = linklevel_p_w.view(-1)\n",
    "                linklevel_m[:,head*self.walk_len+i] = linklevel_m_w.view(-1)\n",
    "\n",
    "                # graph average of returning probabilities\n",
    "                diag_ele_p = torch.gather(x_p,1,index)\n",
    "                diag_ele_m = torch.gather(x_m,1,index)\n",
    "\n",
    "                graphlevel_p = scatter_add(diag_ele_p, batch, dim = 0)\n",
    "                graphlevel_m = scatter_add(diag_ele_m, batch, dim = 0)\n",
    "\n",
    "                graphlevel[:,head*self.walk_len+i] = (graphlevel_p-graphlevel_m).view(-1)\n",
    "         \n",
    "        feature_list = graphlevel \n",
    "        feature_list = torch.cat((feature_list,omega),dim=1)\n",
    "        feature_list = torch.cat((feature_list,nodelevel_p),dim=1)\n",
    "        feature_list = torch.cat((feature_list,nodelevel_m),dim=1)\n",
    "        feature_list = torch.cat((feature_list,linklevel_p),dim=1)\n",
    "        feature_list = torch.cat((feature_list,linklevel_m),dim=1)\n",
    "\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j  \n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    # adopt a MLP as classifier for graphs\n",
    "    def __init__(self,input_size,MSE=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.nn = nn.BatchNorm1d(input_size)\n",
    "        self.linear1 = torch.nn.Linear(input_size,input_size*20)\n",
    "        self.linear2 = torch.nn.Linear(input_size*20,input_size*20)\n",
    "        self.linear3 = torch.nn.Linear(input_size*20,input_size*10)\n",
    "        self.linear4 = torch.nn.Linear(input_size*10,input_size)\n",
    "        self.linear5 = torch.nn.Linear(input_size,1)\n",
    "        self.act= nn.ReLU()\n",
    "        self.MSE=MSE\n",
    "        self.norm1 = nn.BatchNorm1d(input_size*20)\n",
    "        self.norm2 = nn.BatchNorm1d(input_size*20)\n",
    "        self.norm3 = nn.BatchNorm1d(input_size*10)\n",
    "        self.norm4 = nn.BatchNorm1d(input_size)\n",
    "    def forward(self, x):\n",
    "        out= self.nn(x)\n",
    "        out= self.linear1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm1(out)\n",
    "        out= self.linear2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm3(out)\n",
    "        out = self.linear4(out)\n",
    "        out = self.act(out)\n",
    "        out = self.norm4(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.linear5(out)\n",
    "        #out = torch.sigmoid(out)\n",
    "        if self.MSE:\n",
    "            out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd176aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader,epoch):\n",
    "    model.train()\n",
    "    loss_epoch=0\n",
    "    for data in tqdm(loader,desc=\"train\"):  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        label= data.label\n",
    "        out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "        torch.cuda.empty_cache()\n",
    "        loss = criterion(out.view(-1), label)  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        loss_epoch=loss_epoch+loss.item()\n",
    "    return loss_epoch/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c6c7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader,data_type='test'):\n",
    "    model.eval()\n",
    "    scores = torch.tensor([])\n",
    "    labels = torch.tensor([])\n",
    "    loss_total=0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader,desc='test:'+data_type):  # Iterate in batches over the training/test dataset.\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "            loss = criterion(out.view(-1), data.label)\n",
    "            out = out.cpu().clone().detach()\n",
    "            scores = torch.cat((scores,out),dim = 0)\n",
    "            labels = torch.cat((labels,data.label.view(-1,1).cpu().clone().detach()),dim = 0)\n",
    "        scores = scores.cpu().clone().detach().numpy()\n",
    "        labels = labels.cpu().clone().detach().numpy()\n",
    "        loss_total=loss_total+loss.item()\n",
    "        return roc_auc_score(labels, scores), average_precision_score(labels, scores),loss_total,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe26ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_len = 7\n",
    "lr = 0.005\n",
    "heads = 2\n",
    "hidden_channels = 32\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "z_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f2c86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkPred(in_channels = num_features, hidden_channels = hidden_channels,\\\n",
    "    heads = heads, walk_len = walk_len, drnl = False,z_max = z_max, MSE= True).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=0.005)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "#criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "040d522d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:20<00:00,  5.94it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss : 0.2175,     Val Loss : 0.2783, Val AUC: 0.6346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.04it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss : 0.2142,     Val Loss : 0.2177, Val AUC: 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.00it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss : 0.2112,     Val Loss : 0.2500, Val AUC: 0.6892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:13<00:00,  8.92it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss : 0.2078,     Val Loss : 0.2537, Val AUC: 0.7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.20it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss : 0.2042,     Val Loss : 0.2832, Val AUC: 0.6108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.55it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss : 0.2051,     Val Loss : 0.2623, Val AUC: 0.7396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.72it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss : 0.2038,     Val Loss : 0.1572, Val AUC: 0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.11it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss : 0.2023,     Val Loss : 0.2519, Val AUC: 0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.78it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 23.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss : 0.2027,     Val Loss : 0.2269, Val AUC: 0.7643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.03it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss : 0.2042,     Val Loss : 0.3327, Val AUC: 0.7433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.10it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss : 0.1998,     Val Loss : 0.1875, Val AUC: 0.7421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.21it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss : 0.2026,     Val Loss : 0.1757, Val AUC: 0.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.36it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss : 0.2024,     Val Loss : 0.4940, Val AUC: 0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:13<00:00,  8.75it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss : 0.2021,     Val Loss : 0.2014, Val AUC: 0.7487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.29it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 18.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss : 0.2028,     Val Loss : 0.2236, Val AUC: 0.7498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.36it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss : 0.1989,     Val Loss : 0.2018, Val AUC: 0.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:13<00:00,  8.66it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss : 0.2021,     Val Loss : 0.1739, Val AUC: 0.7436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.97it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Loss : 0.2017,     Val Loss : 0.3522, Val AUC: 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.99it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Loss : 0.2016,     Val Loss : 0.1319, Val AUC: 0.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.23it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Loss : 0.1998,     Val Loss : 0.2991, Val AUC: 0.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.34it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss : 0.2017,     Val Loss : 0.3808, Val AUC: 0.7465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.73it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Loss : 0.2018,     Val Loss : 0.1984, Val AUC: 0.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.02it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 21.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Loss : 0.2009,     Val Loss : 0.3441, Val AUC: 0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.00it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Loss : 0.2030,     Val Loss : 0.1749, Val AUC: 0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.28it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss : 0.2014,     Val Loss : 0.1612, Val AUC: 0.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.28it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Loss : 0.1977,     Val Loss : 0.1735, Val AUC: 0.7348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.16it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Loss : 0.2031,     Val Loss : 0.7721, Val AUC: 0.7470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:18<00:00,  6.60it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Loss : 0.2007,     Val Loss : 0.1351, Val AUC: 0.7468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:18<00:00,  6.55it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 16.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Loss : 0.2020,     Val Loss : 0.1725, Val AUC: 0.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:17<00:00,  6.72it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:01<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Loss : 0.2031,     Val Loss : 0.3490, Val AUC: 0.7473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:22<00:00,  5.36it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:01<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Loss : 0.2009,     Val Loss : 0.2562, Val AUC: 0.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:18<00:00,  6.48it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 031, Loss : 0.2033,     Val Loss : 0.2430, Val AUC: 0.7508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:18<00:00,  6.60it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 032, Loss : 0.2031,     Val Loss : 0.1669, Val AUC: 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.57it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 033, Loss : 0.2027,     Val Loss : 0.2061, Val AUC: 0.7379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.23it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss : 0.2034,     Val Loss : 0.1933, Val AUC: 0.7465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.72it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 035, Loss : 0.2035,     Val Loss : 0.1283, Val AUC: 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.92it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 036, Loss : 0.2012,     Val Loss : 0.0814, Val AUC: 0.7469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.81it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 037, Loss : 0.2055,     Val Loss : 0.2173, Val AUC: 0.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.47it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 038, Loss : 0.2012,     Val Loss : 0.2640, Val AUC: 0.7480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:13<00:00,  8.60it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 039, Loss : 0.2020,     Val Loss : 0.2128, Val AUC: 0.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.32it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Loss : 0.2043,     Val Loss : 0.3651, Val AUC: 0.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.33it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 041, Loss : 0.2048,     Val Loss : 0.2438, Val AUC: 0.7192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.03it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 042, Loss : 0.2042,     Val Loss : 0.1857, Val AUC: 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:15<00:00,  7.97it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 043, Loss : 0.2020,     Val Loss : 0.3409, Val AUC: 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.02it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 044, Loss : 0.2046,     Val Loss : 0.2413, Val AUC: 0.7522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.06it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 18.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 045, Loss : 0.2053,     Val Loss : 0.1237, Val AUC: 0.7226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.47it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 046, Loss : 0.2029,     Val Loss : 0.1861, Val AUC: 0.7396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.31it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 19.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 047, Loss : 0.2041,     Val Loss : 0.1703, Val AUC: 0.7516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:13<00:00,  8.59it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 048, Loss : 0.2052,     Val Loss : 0.1430, Val AUC: 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 120/120 [00:14<00:00,  8.17it/s]\n",
      "test:val: 100%|██████████| 14/14 [00:00<00:00, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 049, Loss : 0.2057,     Val Loss : 0.1669, Val AUC: 0.7480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Best_Val_fromloss=1e10\n",
    "Final_Test_AUC_fromloss=0\n",
    "Final_Test_AP_fromloss=0\n",
    "\n",
    "Best_Val_fromAUC=0\n",
    "Final_Test_AUC_fromAUC=0\n",
    "Final_Test_AP_fromAUC=0\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    loss_epoch = train(train_loader,epoch)\n",
    "    val_auc, val_ap, val_loss,_ = test(val_loader,data_type='val')\n",
    "    #test_auc,test_ap,_,_ = test(test_loader,data_type='test')\n",
    "    if val_loss < Best_Val_fromloss:\n",
    "        Best_Val_fromloss = val_loss\n",
    "        #Final_Test_AUC_fromloss = test_auc\n",
    "        #Final_Test_AP_fromloss = test_ap\n",
    "\n",
    "    if val_auc > Best_Val_fromAUC:\n",
    "        Best_Val_fromAUC = val_auc\n",
    "        #Final_Test_AUC_fromAUC = test_auc\n",
    "        #Final_Test_AP_fromAUC = test_ap\n",
    "    print(f'Epoch: {epoch:03d}, Loss : {loss_epoch:.4f},\\\n",
    "     Val Loss : {val_loss:.4f}, Val AUC: {val_auc:.4f}')\n",
    "    '''\n",
    "    print(f'Epoch: {epoch:03d}, Loss : {loss_epoch:.4f},\\\n",
    "     Val Loss : {val_loss:.4f}, Val AUC: {val_auc:.4f},\\\n",
    "      Test AUC: {test_auc:.4f}, Picked AUC:{Final_Test_AUC_fromAUC:.4f}')\n",
    "print(f'From loss: Final Test AUC: {Final_Test_AUC_fromloss:.4f}, Final Test AP: {Final_Test_AP_fromloss:.4f}')\n",
    "print(f'From AUC: Final Test AUC: {Final_Test_AUC_fromAUC:.4f}, Final Test AP: {Final_Test_AP_fromAUC:.4f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed8e5ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test:: 100%|██████████| 68/68 [00:03<00:00, 17.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2172, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "scores = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "loss_total=0\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader,desc='test:'):  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_mask, data.batch, data.z)\n",
    "        out = out.cpu().clone().detach()\n",
    "        scores = torch.cat((scores,out),dim = 0)\n",
    "    scores = scores.cpu().clone().detach().numpy()\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8eda224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37016982, 0.4772248 , 0.4741943 , ..., 0.37016976, 0.37016982,\n",
       "       0.6684545 ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97c91cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E10559</td>\n",
       "      <td>0.370170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E4849</td>\n",
       "      <td>0.477225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3964</td>\n",
       "      <td>0.474194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E542</td>\n",
       "      <td>0.498574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E331</td>\n",
       "      <td>0.434714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>E2524</td>\n",
       "      <td>0.370170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>E4324</td>\n",
       "      <td>0.370170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>E1384</td>\n",
       "      <td>0.370170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>E7582</td>\n",
       "      <td>0.370170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>E5209</td>\n",
       "      <td>0.668455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2172 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      prob\n",
       "0     E10559  0.370170\n",
       "1      E4849  0.477225\n",
       "2      E3964  0.474194\n",
       "3       E542  0.498574\n",
       "4       E331  0.434714\n",
       "...      ...       ...\n",
       "2167   E2524  0.370170\n",
       "2168   E4324  0.370170\n",
       "2169   E1384  0.370170\n",
       "2170   E7582  0.370170\n",
       "2171   E5209  0.668455\n",
       "\n",
       "[2172 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Upload['prob'] = scores.flatten().astype('float64')\n",
    "Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e14e0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upload.to_csv('output/1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7433dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
